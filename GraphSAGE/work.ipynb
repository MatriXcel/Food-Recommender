{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import ast \n",
    "import dgl\n",
    "import gensim \n",
    "import logging\n",
    "import os\n",
    "# import re\n",
    "import pickle\n",
    "import sys\n",
    "import torch\n",
    "import tqdm\n",
    "\n",
    "import dgl.function as nn\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import pygraphviz as pgv\n",
    "import scipy.sparse as ssp\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from collections import defaultdict \n",
    "\n",
    "from dgl.data import DGLDataset\n",
    "from dgl.dataloading import negative_sampler\n",
    "from dgl.nn import SAGEConv \n",
    "from dgl.nn.pytorch import RelGraphConv\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# local imports\n",
    "sys.path.insert(0, 'graph-rec/src/pinsage')\n",
    "from builder import PandasGraphBuilder\n",
    "from data_utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s: ', level=logging.INFO)\n",
    "\n",
    "logger = logging.getLogger('bum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version: 3.8.10\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(\"Version: {}\".format(python_version()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove items in list not in another given list\n",
    "def filter_list(list_to_filter: list, set_to_check: frozenset):\n",
    "    return list(filter(lambda item: item in set_to_check, list_to_filter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw interactions data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>date</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38094</td>\n",
       "      <td>40893</td>\n",
       "      <td>2003-02-17</td>\n",
       "      <td>4</td>\n",
       "      <td>Great with a salad. Cooked on top of stove for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1293707</td>\n",
       "      <td>40893</td>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>5</td>\n",
       "      <td>So simple, so delicious! Great for chilly fall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8937</td>\n",
       "      <td>44394</td>\n",
       "      <td>2002-12-01</td>\n",
       "      <td>4</td>\n",
       "      <td>This worked very well and is EASY.  I used not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>126440</td>\n",
       "      <td>85009</td>\n",
       "      <td>2010-02-27</td>\n",
       "      <td>5</td>\n",
       "      <td>I made the Mexican topping and took it to bunk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57222</td>\n",
       "      <td>85009</td>\n",
       "      <td>2011-10-01</td>\n",
       "      <td>5</td>\n",
       "      <td>Made the cheddar bacon topping, adding a sprin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  recipe_id        date  rating  \\\n",
       "0    38094      40893  2003-02-17       4   \n",
       "1  1293707      40893  2011-12-21       5   \n",
       "2     8937      44394  2002-12-01       4   \n",
       "3   126440      85009  2010-02-27       5   \n",
       "4    57222      85009  2011-10-01       5   \n",
       "\n",
       "                                              review  \n",
       "0  Great with a salad. Cooked on top of stove for...  \n",
       "1  So simple, so delicious! Great for chilly fall...  \n",
       "2  This worked very well and is EASY.  I used not...  \n",
       "3  I made the Mexican topping and took it to bunk...  \n",
       "4  Made the cheddar bacon topping, adding a sprin...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_data = pd.read_csv('gcn/archive/RAW_interactions.csv')\n",
    "interactions_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Some formatting work on interactions data\n",
    "\"\"\"\n",
    "interactions_data.iloc[1].review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all users that have reviewed a recipe\n",
    "users_with_interactions = frozenset(interactions_data.user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = interactions_data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw recipe data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>minutes</th>\n",
       "      <th>contributor_id</th>\n",
       "      <th>submitted</th>\n",
       "      <th>tags</th>\n",
       "      <th>nutrition</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>steps</th>\n",
       "      <th>description</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>n_ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arriba   baked winter squash mexican style</td>\n",
       "      <td>137739</td>\n",
       "      <td>55</td>\n",
       "      <td>47892</td>\n",
       "      <td>2005-09-16</td>\n",
       "      <td>['60-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[51.5, 0.0, 13.0, 0.0, 2.0, 0.0, 4.0]</td>\n",
       "      <td>11</td>\n",
       "      <td>['make a choice and proceed with recipe', 'dep...</td>\n",
       "      <td>autumn is my favorite time of year to cook! th...</td>\n",
       "      <td>['winter squash', 'mexican seasoning', 'mixed ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a bit different  breakfast pizza</td>\n",
       "      <td>31490</td>\n",
       "      <td>30</td>\n",
       "      <td>26278</td>\n",
       "      <td>2002-06-17</td>\n",
       "      <td>['30-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[173.4, 18.0, 0.0, 17.0, 22.0, 35.0, 1.0]</td>\n",
       "      <td>9</td>\n",
       "      <td>['preheat oven to 425 degrees f', 'press dough...</td>\n",
       "      <td>this recipe calls for the crust to be prebaked...</td>\n",
       "      <td>['prepared pizza crust', 'sausage patty', 'egg...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all in the kitchen  chili</td>\n",
       "      <td>112140</td>\n",
       "      <td>130</td>\n",
       "      <td>196586</td>\n",
       "      <td>2005-02-25</td>\n",
       "      <td>['time-to-make', 'course', 'preparation', 'mai...</td>\n",
       "      <td>[269.8, 22.0, 32.0, 48.0, 39.0, 27.0, 5.0]</td>\n",
       "      <td>6</td>\n",
       "      <td>['brown ground beef in large pot', 'add choppe...</td>\n",
       "      <td>this modified version of 'mom's' chili was a h...</td>\n",
       "      <td>['ground beef', 'yellow onions', 'diced tomato...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         name      id  minutes  \\\n",
       "0  arriba   baked winter squash mexican style  137739       55   \n",
       "1            a bit different  breakfast pizza   31490       30   \n",
       "2                   all in the kitchen  chili  112140      130   \n",
       "\n",
       "   contributor_id   submitted  \\\n",
       "0           47892  2005-09-16   \n",
       "1           26278  2002-06-17   \n",
       "2          196586  2005-02-25   \n",
       "\n",
       "                                                tags  \\\n",
       "0  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
       "1  ['30-minutes-or-less', 'time-to-make', 'course...   \n",
       "2  ['time-to-make', 'course', 'preparation', 'mai...   \n",
       "\n",
       "                                    nutrition  n_steps  \\\n",
       "0       [51.5, 0.0, 13.0, 0.0, 2.0, 0.0, 4.0]       11   \n",
       "1   [173.4, 18.0, 0.0, 17.0, 22.0, 35.0, 1.0]        9   \n",
       "2  [269.8, 22.0, 32.0, 48.0, 39.0, 27.0, 5.0]        6   \n",
       "\n",
       "                                               steps  \\\n",
       "0  ['make a choice and proceed with recipe', 'dep...   \n",
       "1  ['preheat oven to 425 degrees f', 'press dough...   \n",
       "2  ['brown ground beef in large pot', 'add choppe...   \n",
       "\n",
       "                                         description  \\\n",
       "0  autumn is my favorite time of year to cook! th...   \n",
       "1  this recipe calls for the crust to be prebaked...   \n",
       "2  this modified version of 'mom's' chili was a h...   \n",
       "\n",
       "                                         ingredients  n_ingredients  \n",
       "0  ['winter squash', 'mexican seasoning', 'mixed ...              7  \n",
       "1  ['prepared pizza crust', 'sausage patty', 'egg...              6  \n",
       "2  ['ground beef', 'yellow onions', 'diced tomato...             13  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe_data = pd.read_csv('gcn/archive/RAW_recipes.csv')\n",
    "recipe_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231637"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many unique recipes do we have? \n",
    "len(recipe_data.id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>minutes</th>\n",
       "      <th>contributor_id</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>n_ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>231637.000000</td>\n",
       "      <td>2.316370e+05</td>\n",
       "      <td>2.316370e+05</td>\n",
       "      <td>231637.000000</td>\n",
       "      <td>231637.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>222014.708984</td>\n",
       "      <td>9.398546e+03</td>\n",
       "      <td>5.534885e+06</td>\n",
       "      <td>9.765499</td>\n",
       "      <td>9.051153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>141206.635626</td>\n",
       "      <td>4.461963e+06</td>\n",
       "      <td>9.979141e+07</td>\n",
       "      <td>5.995128</td>\n",
       "      <td>3.734796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.700000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>99944.000000</td>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>5.690500e+04</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>207249.000000</td>\n",
       "      <td>4.000000e+01</td>\n",
       "      <td>1.736140e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>333816.000000</td>\n",
       "      <td>6.500000e+01</td>\n",
       "      <td>3.982750e+05</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>537716.000000</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.002290e+09</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>43.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id       minutes  contributor_id        n_steps  \\\n",
       "count  231637.000000  2.316370e+05    2.316370e+05  231637.000000   \n",
       "mean   222014.708984  9.398546e+03    5.534885e+06       9.765499   \n",
       "std    141206.635626  4.461963e+06    9.979141e+07       5.995128   \n",
       "min        38.000000  0.000000e+00    2.700000e+01       0.000000   \n",
       "25%     99944.000000  2.000000e+01    5.690500e+04       6.000000   \n",
       "50%    207249.000000  4.000000e+01    1.736140e+05       9.000000   \n",
       "75%    333816.000000  6.500000e+01    3.982750e+05      12.000000   \n",
       "max    537716.000000  2.147484e+09    2.002290e+09     145.000000   \n",
       "\n",
       "       n_ingredients  \n",
       "count  231637.000000  \n",
       "mean        9.051153  \n",
       "std         3.734796  \n",
       "min         1.000000  \n",
       "25%         6.000000  \n",
       "50%         9.000000  \n",
       "75%        11.000000  \n",
       "max        43.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Some formatting work on recipe data\n",
    "\"\"\"\n",
    "# rename columns to have matching column names between datasets\n",
    "recipe_data = recipe_data.rename(columns={\"id\": \"recipe_id\", \"contributor_id\": \"user_id\"})\n",
    "\n",
    "# turn strings to lists\n",
    "# recipe_data['tags'] = recipe_data.tags.transform(ast.literal_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num users that contributed a recipe = 27926\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'users_with_interactions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2fccdc1e5055>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Users that both reviewed and contributed a recipe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0musers_that_reviewed_and_submitted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0musers_with_interactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers_that_contributed_a_recipe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Num users that both reviewed and contributed = {len(users_that_reviewed_and_contributed)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'users_with_interactions' is not defined"
     ]
    }
   ],
   "source": [
    "# users that contributed a recipe\n",
    "users_that_contributed_a_recipe = recipe_data.user_id.unique()\n",
    "print(f\"Num users that contributed a recipe = {len(users_that_contributed_a_recipe)}\")\n",
    "\n",
    "# Users that both reviewed and contributed a recipe\n",
    "users_that_reviewed_and_submitted = users_with_interactions.intersection(users_that_contributed_a_recipe)\n",
    "print(f'Num users that both reviewed and contributed = {len(users_that_reviewed_and_contributed)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'recipe_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-23a03b4a6c59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \"\"\"\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# reviewed_recipes = recipes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mrecipes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'recipe_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecipes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecipe_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrecipes_with_reviews\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mrecipes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mrecipes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecipes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'recipe_id'"
     ]
    }
   ],
   "source": [
    "\"\"\" keep only recipes that have received at least one review from \n",
    "    a user who has contributed at least one recipe\n",
    "\"\"\"\n",
    "# reviewed_recipes = recipes\n",
    "recipes['recipe_id'] = recipes.recipe_id.apply(lambda x: x if x in recipes_with_reviews else np.nan)\n",
    "recipes.dropna(inplace=True)\n",
    "recipes = recipes.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>minutes</th>\n",
       "      <th>user_id</th>\n",
       "      <th>submitted</th>\n",
       "      <th>tags</th>\n",
       "      <th>nutrition</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>steps</th>\n",
       "      <th>description</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>n_ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arriba   baked winter squash mexican style</td>\n",
       "      <td>137739</td>\n",
       "      <td>55</td>\n",
       "      <td>47892</td>\n",
       "      <td>2005-09-16</td>\n",
       "      <td>['60-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[51.5, 0.0, 13.0, 0.0, 2.0, 0.0, 4.0]</td>\n",
       "      <td>11</td>\n",
       "      <td>['make a choice and proceed with recipe', 'dep...</td>\n",
       "      <td>autumn is my favorite time of year to cook! th...</td>\n",
       "      <td>['winter squash', 'mexican seasoning', 'mixed ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         name  recipe_id  minutes  user_id  \\\n",
       "0  arriba   baked winter squash mexican style     137739       55    47892   \n",
       "\n",
       "    submitted                                               tags  \\\n",
       "0  2005-09-16  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
       "\n",
       "                               nutrition  n_steps  \\\n",
       "0  [51.5, 0.0, 13.0, 0.0, 2.0, 0.0, 4.0]       11   \n",
       "\n",
       "                                               steps  \\\n",
       "0  ['make a choice and proceed with recipe', 'dep...   \n",
       "\n",
       "                                         description  \\\n",
       "0  autumn is my favorite time of year to cook! th...   \n",
       "\n",
       "                                         ingredients  n_ingredients  \n",
       "0  ['winter squash', 'mexican seasoning', 'mixed ...              7  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes = recipe_data\n",
    "recipes.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all recipes that have recieved at least one review\n",
    "recipes_with_reviews = frozenset(interactions_data.recipe_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename some columns to have matching column names between dataframes\n",
    "recipes_df = recipes.rename(columns={'id': 'recipe_id',\n",
    "                                     'contributor_id': 'user_id'}).set_index('recipe_id')\n",
    "\n",
    "# order columns in the same way they appear in interactions dataframe\n",
    "recipes_df = recipes_df.reindex(index=interactions.recipe_id)\n",
    "recipes_df = recipes_df.dropna().astype(str).drop_duplicates().reset_index()\n",
    "\n",
    "# remove recipes that haven't been interacted with? todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'recipes_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-2a2feda4555d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrecipes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecipes_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'recipes_df' is not defined"
     ]
    }
   ],
   "source": [
    "recipes = recipes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a user-submitted-recipe df\n",
    "submitted_df = recipes_df[['user_id', 'recipe_id']].drop_duplicates().dropna().reset_index(drop=True)\n",
    "\n",
    "len(set(np.concatenate((review_df.user_id.unique(), submitted_df.user_id.unique()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 47892,  26278, 196586,  68585,  41706])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.LongTensor(recipes.user_id[:5].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all recipes\n",
    "Get all unique recipes. And if a recipe hasnb't been interacted with, we can remove it for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "unique_users = frozenset(interactions_data.user_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231637"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove recipes without reviews\n",
    "# interactions_data[~interactions_data.recipe_id.isin(unique_recipes)]\n",
    "# user_data = user_data.copy()[~user_data.u.isin(unique_users)]\n",
    "recipe_data[~recipe_data.recipe_id.isin(recipes_with_reviews)]\n",
    "len(recipe_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter users without ratings. \n",
    "users_in_interactions = frozenset(recipe_data.user_id.unique())\n",
    "print(len(users_in_interactions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(unique_users))\n",
    "print(len(users_in_interactions))\n",
    "# print(len(unique_users-users_in_interactions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing for GraphSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>date</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [user_id, recipe_id, date, rating, review]\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep users that contributed AND also reviewed at least one recipe\n",
    "#interactions['user_id'] = interactions['user_id'].apply(lambda x: x if x in users_that_reviewed_and_contributed else np.nan)\n",
    "#interactions.dropna(inplace=True)\n",
    "interactions[~interactions.recipe_id.isin(recipe_data.recipe_id.unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions.head(4)\n",
    "print(len(interactions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>date</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38094</td>\n",
       "      <td>40893</td>\n",
       "      <td>2003-02-17</td>\n",
       "      <td>4</td>\n",
       "      <td>Great with a salad. Cooked on top of stove for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1293707</td>\n",
       "      <td>40893</td>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>5</td>\n",
       "      <td>So simple, so delicious! Great for chilly fall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8937</td>\n",
       "      <td>44394</td>\n",
       "      <td>2002-12-01</td>\n",
       "      <td>4</td>\n",
       "      <td>This worked very well and is EASY.  I used not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>126440</td>\n",
       "      <td>85009</td>\n",
       "      <td>2010-02-27</td>\n",
       "      <td>5</td>\n",
       "      <td>I made the Mexican topping and took it to bunk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57222</td>\n",
       "      <td>85009</td>\n",
       "      <td>2011-10-01</td>\n",
       "      <td>5</td>\n",
       "      <td>Made the cheddar bacon topping, adding a sprin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132362</th>\n",
       "      <td>116593</td>\n",
       "      <td>72730</td>\n",
       "      <td>2003-12-09</td>\n",
       "      <td>0</td>\n",
       "      <td>Another approach is to start making sauce with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132363</th>\n",
       "      <td>583662</td>\n",
       "      <td>386618</td>\n",
       "      <td>2009-09-29</td>\n",
       "      <td>5</td>\n",
       "      <td>These were so delicious!  My husband and I tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132364</th>\n",
       "      <td>157126</td>\n",
       "      <td>78003</td>\n",
       "      <td>2008-06-23</td>\n",
       "      <td>5</td>\n",
       "      <td>WOW!  Sometimes I don't take the time to rate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132365</th>\n",
       "      <td>53932</td>\n",
       "      <td>78003</td>\n",
       "      <td>2009-01-11</td>\n",
       "      <td>4</td>\n",
       "      <td>Very good!  I used regular port as well.  The ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132366</th>\n",
       "      <td>2001868099</td>\n",
       "      <td>78003</td>\n",
       "      <td>2017-12-18</td>\n",
       "      <td>5</td>\n",
       "      <td>I am so glad I googled and found this here. Th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1132198 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            user_id  recipe_id        date  rating  \\\n",
       "0             38094      40893  2003-02-17       4   \n",
       "1           1293707      40893  2011-12-21       5   \n",
       "2              8937      44394  2002-12-01       4   \n",
       "3            126440      85009  2010-02-27       5   \n",
       "4             57222      85009  2011-10-01       5   \n",
       "...             ...        ...         ...     ...   \n",
       "1132362      116593      72730  2003-12-09       0   \n",
       "1132363      583662     386618  2009-09-29       5   \n",
       "1132364      157126      78003  2008-06-23       5   \n",
       "1132365       53932      78003  2009-01-11       4   \n",
       "1132366  2001868099      78003  2017-12-18       5   \n",
       "\n",
       "                                                    review  \n",
       "0        Great with a salad. Cooked on top of stove for...  \n",
       "1        So simple, so delicious! Great for chilly fall...  \n",
       "2        This worked very well and is EASY.  I used not...  \n",
       "3        I made the Mexican topping and took it to bunk...  \n",
       "4        Made the cheddar bacon topping, adding a sprin...  \n",
       "...                                                    ...  \n",
       "1132362  Another approach is to start making sauce with...  \n",
       "1132363  These were so delicious!  My husband and I tru...  \n",
       "1132364  WOW!  Sometimes I don't take the time to rate ...  \n",
       "1132365  Very good!  I used regular port as well.  The ...  \n",
       "1132366  I am so glad I googled and found this here. Th...  \n",
       "\n",
       "[1132198 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prepared pizza crust',\n",
       " 'sausage patty',\n",
       " 'eggs',\n",
       " 'milk',\n",
       " 'salt and pepper',\n",
       " 'cheese']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert string data to actual lists\n",
    "recipes['ingredients'] = recipes.ingredients.apply(ast.literal_eval)\n",
    "recipes.ingredients.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes.description.iloc[1]\n",
    "recipes.ingredients.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df for rating given (and review?)\n",
    "review_df = interactions[['user_id', 'recipe_id', 'rating', 'review']].astype({\"user_id\": int,\n",
    "                                                                               \"recipe_id\": int,\n",
    "                                                                               \"rating\": int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>date</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>user_id_contig</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38094</td>\n",
       "      <td>40893</td>\n",
       "      <td>2003-02-17</td>\n",
       "      <td>4</td>\n",
       "      <td>Great with a salad. Cooked on top of stove for...</td>\n",
       "      <td>19262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1293707</td>\n",
       "      <td>40893</td>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>5</td>\n",
       "      <td>So simple, so delicious! Great for chilly fall...</td>\n",
       "      <td>122399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8937</td>\n",
       "      <td>44394</td>\n",
       "      <td>2002-12-01</td>\n",
       "      <td>4</td>\n",
       "      <td>This worked very well and is EASY.  I used not...</td>\n",
       "      <td>4482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  recipe_id        date  rating  \\\n",
       "0    38094      40893  2003-02-17       4   \n",
       "1  1293707      40893  2011-12-21       5   \n",
       "2     8937      44394  2002-12-01       4   \n",
       "\n",
       "                                              review  user_id_contig  \n",
       "0  Great with a salad. Cooked on top of stove for...           19262  \n",
       "1  So simple, so delicious! Great for chilly fall...          122399  \n",
       "2  This worked very well and is EASY.  I used not...            4482  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We need to remap IDs for recipes and users to contiguous numbers so that the resultilng graph has a representative number of nodes to number of items in the dataset. \n",
    "\n",
    "This is because dgl uses the ids provided to figure out how many vertices are in the graph. A graph created with 2 vertices with IDs 10 and 11 will result in `|V| = max(10, 11) + 1` = `12` vertices. So we need to start with IDs from `0` or `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236568\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Map IDs in order they appear to numbers 0 to 1.\n",
    "'''\n",
    "_id = 0\n",
    "# first get the unique user IDs. Remember some users may have \n",
    "# only reviewed or contributed a recipe but not both, so we need \n",
    "# to look at both datasets to get all users\n",
    "# all_users = set(np.concatenate((review_df.user_id.unique(), submitted_df.user_id.unique())))\n",
    "all_users = set(np.concatenate((interactions.user_id.unique(), recipes.user_id.unique())))\n",
    "\n",
    "user_id_to_contig_num_map = {}\n",
    "contig_id_to_user_id_map = {}\n",
    "for user in all_users:\n",
    "    user_id_to_contig_num_map[user] = _id\n",
    "    contig_id_to_user_id_map[_id] = user\n",
    "    \n",
    "    _id = _id + 1\n",
    "\n",
    "print(_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-4e291841a9df>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  interactions['user_id_contig'] = interactions.user_id.apply(lambda x: user_id_to_contig_num_map[x])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Assign contiguous IDs to dataframe \n",
    "'''\n",
    "recipes['user_id_contig'] = recipes.user_id.apply(lambda x: user_id_to_contig_num_map[x])\n",
    "interactions['user_id_contig'] = interactions.user_id.apply(lambda x: user_id_to_contig_num_map[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Create a similar mapping for recipes\n",
    "'''\n",
    "r_id = 0\n",
    "all_recipes = set(np.concatenate((recipes.recipe_id.unique(), interactions.recipe_id.unique())))\n",
    "\n",
    "recipe_id_to_contig_map = {}\n",
    "contig_id_to_recipe_id_map = {}\n",
    "\n",
    "for recipe in all_recipes:\n",
    "    recipe_id_to_contig_map[recipe] = r_id\n",
    "    contig_id_to_recipe_id_map[r_id] = recipe\n",
    "    \n",
    "    r_id = r_id + 1\n",
    "r_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-30-d08032cc5718>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  interactions['recipe_id_contig'] = interactions['recipe_id'].apply(lambda x: recipe_id_to_contig_map[x])\n"
     ]
    }
   ],
   "source": [
    "''' Assign contiguos IDs '''\n",
    "recipes['recipe_id_contig'] = recipes['recipe_id'].apply(lambda x: recipe_id_to_contig_map[x])\n",
    "interactions['recipe_id_contig'] = interactions['recipe_id'].apply(lambda x: recipe_id_to_contig_map[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['bit', 'different', 'breakfast', 'pizza'], tags=[17776]),\n",
       " TaggedDocument(words=['all', 'in', 'the', 'kitchen', 'chili'], tags=[66030]),\n",
       " TaggedDocument(words=['arriba', 'baked', 'winter', 'squash', 'mexican', 'style'], tags=[80434])]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes.head(1)\n",
    "[TaggedDocument(simple_preprocess(str(row[1]['name'])),\n",
    "                                 [row[1]['recipe_id_contig']])\n",
    "                  for row in recipes[:3].sort_values(by=['recipe_id_contig']).iterrows()]\n",
    "# recipes.name.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recipe vertex features: recipe names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>minutes</th>\n",
       "      <th>user_id</th>\n",
       "      <th>submitted</th>\n",
       "      <th>tags</th>\n",
       "      <th>nutrition</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>steps</th>\n",
       "      <th>description</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>n_ingredients</th>\n",
       "      <th>user_id_contig</th>\n",
       "      <th>recipe_id_contig</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>apple a day  milk shake</td>\n",
       "      <td>5289</td>\n",
       "      <td>0</td>\n",
       "      <td>1533</td>\n",
       "      <td>1999-12-06</td>\n",
       "      <td>[15-minutes-or-less, time-to-make, course, mai...</td>\n",
       "      <td>[160.2, 10.0, 55.0, 3.0, 9.0, 20.0, 7.0]</td>\n",
       "      <td>4</td>\n",
       "      <td>['combine ingredients in blender', 'cover and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['milk', 'vanilla ice cream', 'frozen apple ju...</td>\n",
       "      <td>4</td>\n",
       "      <td>553</td>\n",
       "      <td>2239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>chinese  chop suey</td>\n",
       "      <td>8559</td>\n",
       "      <td>70</td>\n",
       "      <td>4481</td>\n",
       "      <td>2001-01-27</td>\n",
       "      <td>[weeknight, time-to-make, course, main-ingredi...</td>\n",
       "      <td>[395.4, 31.0, 20.0, 29.0, 51.0, 33.0, 8.0]</td>\n",
       "      <td>8</td>\n",
       "      <td>['brown ground meat and onion in a large pot',...</td>\n",
       "      <td>easy one-pot dinner.</td>\n",
       "      <td>['celery', 'onion', 'ground pork', 'soy sauce'...</td>\n",
       "      <td>7</td>\n",
       "      <td>2248</td>\n",
       "      <td>3577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cream  of cauliflower soup  vegan</td>\n",
       "      <td>23850</td>\n",
       "      <td>110</td>\n",
       "      <td>3288</td>\n",
       "      <td>2002-03-28</td>\n",
       "      <td>[lactose, weeknight, time-to-make, course, mai...</td>\n",
       "      <td>[174.2, 4.0, 24.0, 1.0, 15.0, 1.0, 10.0]</td>\n",
       "      <td>10</td>\n",
       "      <td>['heat the oil or margarine in a soup pot and ...</td>\n",
       "      <td>this is a dairy free</td>\n",
       "      <td>['canola oil', 'onion', 'garlic', 'cauliflower...</td>\n",
       "      <td>16</td>\n",
       "      <td>1601</td>\n",
       "      <td>13093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>chinese  candy</td>\n",
       "      <td>23933</td>\n",
       "      <td>15</td>\n",
       "      <td>35268</td>\n",
       "      <td>2002-03-29</td>\n",
       "      <td>[15-minutes-or-less, time-to-make, course, pre...</td>\n",
       "      <td>[232.7, 21.0, 77.0, 4.0, 6.0, 38.0, 8.0]</td>\n",
       "      <td>4</td>\n",
       "      <td>['melt butterscotch chips in heavy saucepan ov...</td>\n",
       "      <td>a little different, and oh so good. i include ...</td>\n",
       "      <td>['butterscotch chips', 'chinese noodles', 'sal...</td>\n",
       "      <td>3</td>\n",
       "      <td>17631</td>\n",
       "      <td>13140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>cream  of spinach soup  vegan</td>\n",
       "      <td>24701</td>\n",
       "      <td>55</td>\n",
       "      <td>3288</td>\n",
       "      <td>2002-04-08</td>\n",
       "      <td>[60-minutes-or-less, time-to-make, course, mai...</td>\n",
       "      <td>[64.8, 3.0, 13.0, 54.0, 4.0, 2.0, 3.0]</td>\n",
       "      <td>10</td>\n",
       "      <td>['in a 3 qt saucepan over medium high heat , s...</td>\n",
       "      <td>thickened with a mix of cooked oats and vegies...</td>\n",
       "      <td>['onion', 'scallion', 'apple juice', 'olive oi...</td>\n",
       "      <td>12</td>\n",
       "      <td>1601</td>\n",
       "      <td>13613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aww  marinated olives</td>\n",
       "      <td>25274</td>\n",
       "      <td>15</td>\n",
       "      <td>21730</td>\n",
       "      <td>2002-04-14</td>\n",
       "      <td>[15-minutes-or-less, time-to-make, course, mai...</td>\n",
       "      <td>[380.7, 53.0, 7.0, 24.0, 6.0, 24.0, 6.0]</td>\n",
       "      <td>4</td>\n",
       "      <td>['toast the fennel seeds and lightly crush the...</td>\n",
       "      <td>my italian mil was thoroughly impressed by my ...</td>\n",
       "      <td>['fennel seeds', 'green olives', 'ripe olives'...</td>\n",
       "      <td>9</td>\n",
       "      <td>10577</td>\n",
       "      <td>13966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a bit different  breakfast pizza</td>\n",
       "      <td>31490</td>\n",
       "      <td>30</td>\n",
       "      <td>26278</td>\n",
       "      <td>2002-06-17</td>\n",
       "      <td>[30-minutes-or-less, time-to-make, course, mai...</td>\n",
       "      <td>[173.4, 18.0, 0.0, 17.0, 22.0, 35.0, 1.0]</td>\n",
       "      <td>9</td>\n",
       "      <td>['preheat oven to 425 degrees f', 'press dough...</td>\n",
       "      <td>this recipe calls for the crust to be prebaked...</td>\n",
       "      <td>['prepared pizza crust', 'sausage patty', 'egg...</td>\n",
       "      <td>6</td>\n",
       "      <td>12889</td>\n",
       "      <td>17776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>fried  potatoes</td>\n",
       "      <td>37073</td>\n",
       "      <td>40</td>\n",
       "      <td>1533</td>\n",
       "      <td>2002-08-13</td>\n",
       "      <td>[60-minutes-or-less, time-to-make, course, mai...</td>\n",
       "      <td>[132.6, 8.0, 4.0, 3.0, 4.0, 5.0, 6.0]</td>\n",
       "      <td>14</td>\n",
       "      <td>['preheat oven to 400 degrees', 'cut the potat...</td>\n",
       "      <td>my husband made these up last week, very tasty...</td>\n",
       "      <td>['red potatoes', 'margarine', 'rosemary']</td>\n",
       "      <td>3</td>\n",
       "      <td>553</td>\n",
       "      <td>21164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>calm your nerves  tonic</td>\n",
       "      <td>39959</td>\n",
       "      <td>5</td>\n",
       "      <td>37449</td>\n",
       "      <td>2002-09-10</td>\n",
       "      <td>[15-minutes-or-less, time-to-make, preparation...</td>\n",
       "      <td>[8.2, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>6</td>\n",
       "      <td>['combine herbs', 'dosage: one-half teaspoonfu...</td>\n",
       "      <td>this will prove a blessing to everyone who tak...</td>\n",
       "      <td>['gentian root', 'scullcap herb', 'burnet root...</td>\n",
       "      <td>5</td>\n",
       "      <td>18871</td>\n",
       "      <td>22936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>better than sex  strawberries</td>\n",
       "      <td>42198</td>\n",
       "      <td>1460</td>\n",
       "      <td>41531</td>\n",
       "      <td>2002-10-03</td>\n",
       "      <td>[weeknight, time-to-make, course, main-ingredi...</td>\n",
       "      <td>[734.1, 66.0, 199.0, 10.0, 10.0, 117.0, 28.0]</td>\n",
       "      <td>8</td>\n",
       "      <td>['crush vanilla wafers into fine crumbs and li...</td>\n",
       "      <td>simple but sexy. this was in my local newspape...</td>\n",
       "      <td>['vanilla wafers', 'butter', 'powdered sugar',...</td>\n",
       "      <td>7</td>\n",
       "      <td>21277</td>\n",
       "      <td>24281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>chile rellenos</td>\n",
       "      <td>43026</td>\n",
       "      <td>45</td>\n",
       "      <td>52268</td>\n",
       "      <td>2002-10-14</td>\n",
       "      <td>[60-minutes-or-less, time-to-make, course, mai...</td>\n",
       "      <td>[94.0, 10.0, 0.0, 11.0, 11.0, 21.0, 0.0]</td>\n",
       "      <td>9</td>\n",
       "      <td>['drain green chiles', 'sprinkle cornstarch on...</td>\n",
       "      <td>a favorite from a local restaurant no longer i...</td>\n",
       "      <td>['egg roll wrap', 'whole green chilies', 'chee...</td>\n",
       "      <td>5</td>\n",
       "      <td>27025</td>\n",
       "      <td>24774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amish  tomato ketchup  for canning</td>\n",
       "      <td>44061</td>\n",
       "      <td>190</td>\n",
       "      <td>41706</td>\n",
       "      <td>2002-10-25</td>\n",
       "      <td>[weeknight, time-to-make, course, main-ingredi...</td>\n",
       "      <td>[352.9, 1.0, 337.0, 23.0, 3.0, 0.0, 28.0]</td>\n",
       "      <td>5</td>\n",
       "      <td>['mix all ingredients&amp; boil for 2 1 / 2 hours ...</td>\n",
       "      <td>my dh's amish mother raised him on this recipe...</td>\n",
       "      <td>['tomato juice', 'apple cider vinegar', 'sugar...</td>\n",
       "      <td>8</td>\n",
       "      <td>21377</td>\n",
       "      <td>25380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>george s at the cove  black bean soup</td>\n",
       "      <td>44123</td>\n",
       "      <td>90</td>\n",
       "      <td>35193</td>\n",
       "      <td>2002-10-25</td>\n",
       "      <td>[weeknight, time-to-make, course, main-ingredi...</td>\n",
       "      <td>[804.7, 108.0, 26.0, 19.0, 28.0, 214.0, 10.0]</td>\n",
       "      <td>11</td>\n",
       "      <td>['in 1 / 4 cup butter , saute carrots , onion ...</td>\n",
       "      <td>an original recipe created by chef scott meska...</td>\n",
       "      <td>['unsalted butter', 'carrot', 'onion', 'celery...</td>\n",
       "      <td>18</td>\n",
       "      <td>17590</td>\n",
       "      <td>25418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>forgotten  minestrone</td>\n",
       "      <td>47366</td>\n",
       "      <td>495</td>\n",
       "      <td>31871</td>\n",
       "      <td>2002-11-21</td>\n",
       "      <td>[weeknight, time-to-make, course, main-ingredi...</td>\n",
       "      <td>[346.9, 24.0, 18.0, 42.0, 42.0, 30.0, 10.0]</td>\n",
       "      <td>5</td>\n",
       "      <td>['in a slow cooker , combine the first nine in...</td>\n",
       "      <td>this recipe came from a</td>\n",
       "      <td>['beef stew meat', 'water', 'tomatoes', 'beef ...</td>\n",
       "      <td>14</td>\n",
       "      <td>15939</td>\n",
       "      <td>27220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>emotional balance  spice mixture</td>\n",
       "      <td>48156</td>\n",
       "      <td>10</td>\n",
       "      <td>6164</td>\n",
       "      <td>2002-12-09</td>\n",
       "      <td>[15-minutes-or-less, time-to-make, course, cui...</td>\n",
       "      <td>[182.7, 11.0, 4.0, 1.0, 13.0, 4.0, 10.0]</td>\n",
       "      <td>2</td>\n",
       "      <td>['mix the spices together and store in an airt...</td>\n",
       "      <td>really an effective spice blend...i got it in ...</td>\n",
       "      <td>['ground black pepper', 'ground ginger', 'grou...</td>\n",
       "      <td>6</td>\n",
       "      <td>3119</td>\n",
       "      <td>27690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>easiest ever  hollandaise sauce</td>\n",
       "      <td>49262</td>\n",
       "      <td>25</td>\n",
       "      <td>64428</td>\n",
       "      <td>2002-12-19</td>\n",
       "      <td>[30-minutes-or-less, time-to-make, course, mai...</td>\n",
       "      <td>[1290.4, 213.0, 4.0, 53.0, 22.0, 417.0, 1.0]</td>\n",
       "      <td>7</td>\n",
       "      <td>['cut the butter into several pieces and bring...</td>\n",
       "      <td>the secret to this easy hollandaise sauce is i...</td>\n",
       "      <td>['butter', 'lemon, juice of', 'salt', 'white p...</td>\n",
       "      <td>5</td>\n",
       "      <td>33908</td>\n",
       "      <td>28331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>fool the meat eaters  chili</td>\n",
       "      <td>54272</td>\n",
       "      <td>40</td>\n",
       "      <td>40525</td>\n",
       "      <td>2003-02-17</td>\n",
       "      <td>[60-minutes-or-less, time-to-make, course, mai...</td>\n",
       "      <td>[295.6, 3.0, 56.0, 76.0, 32.0, 1.0, 18.0]</td>\n",
       "      <td>9</td>\n",
       "      <td>['rehydrate tvp if needed', 'spray or oil a la...</td>\n",
       "      <td>this recipe was adapted by my mother and mysel...</td>\n",
       "      <td>['vegetarian ground beef', 'garlic', 'onion', ...</td>\n",
       "      <td>12</td>\n",
       "      <td>20702</td>\n",
       "      <td>31396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alouette  potatoes</td>\n",
       "      <td>59389</td>\n",
       "      <td>45</td>\n",
       "      <td>68585</td>\n",
       "      <td>2003-04-14</td>\n",
       "      <td>[60-minutes-or-less, time-to-make, course, mai...</td>\n",
       "      <td>[368.1, 17.0, 10.0, 2.0, 14.0, 8.0, 20.0]</td>\n",
       "      <td>11</td>\n",
       "      <td>['place potatoes in a large pot of lightly sal...</td>\n",
       "      <td>this is a super easy, great tasting, make ahea...</td>\n",
       "      <td>['spreadable cheese with garlic and herbs', 'n...</td>\n",
       "      <td>11</td>\n",
       "      <td>36138</td>\n",
       "      <td>34527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>chicken lickin  good  pork chops</td>\n",
       "      <td>63986</td>\n",
       "      <td>500</td>\n",
       "      <td>14664</td>\n",
       "      <td>2003-06-06</td>\n",
       "      <td>[weeknight, time-to-make, course, main-ingredi...</td>\n",
       "      <td>[105.7, 8.0, 0.0, 26.0, 5.0, 4.0, 3.0]</td>\n",
       "      <td>5</td>\n",
       "      <td>['dredge pork chops in mixture of flour , salt...</td>\n",
       "      <td>here's and old standby i enjoy from time to ti...</td>\n",
       "      <td>['lean pork chops', 'flour', 'salt', 'dry must...</td>\n",
       "      <td>7</td>\n",
       "      <td>7197</td>\n",
       "      <td>37390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>better then bush s  baked beans</td>\n",
       "      <td>67547</td>\n",
       "      <td>2970</td>\n",
       "      <td>85627</td>\n",
       "      <td>2003-07-26</td>\n",
       "      <td>[weeknight, time-to-make, course, main-ingredi...</td>\n",
       "      <td>[462.4, 28.0, 214.0, 69.0, 14.0, 29.0, 23.0]</td>\n",
       "      <td>9</td>\n",
       "      <td>['in a very large sauce pan cover the beans an...</td>\n",
       "      <td>i'd have to say that this is a labor of love d...</td>\n",
       "      <td>['great northern bean', 'chicken bouillon cube...</td>\n",
       "      <td>13</td>\n",
       "      <td>44416</td>\n",
       "      <td>39549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>backyard style  barbecued ribs</td>\n",
       "      <td>67888</td>\n",
       "      <td>120</td>\n",
       "      <td>10404</td>\n",
       "      <td>2003-07-30</td>\n",
       "      <td>[weeknight, time-to-make, course, main-ingredi...</td>\n",
       "      <td>[1109.5, 83.0, 378.0, 275.0, 96.0, 86.0, 36.0]</td>\n",
       "      <td>10</td>\n",
       "      <td>['in a medium saucepan combine all the ingredi...</td>\n",
       "      <td>this recipe is posted by request and was origi...</td>\n",
       "      <td>['pork spareribs', 'soy sauce', 'fresh garlic'...</td>\n",
       "      <td>22</td>\n",
       "      <td>5177</td>\n",
       "      <td>39735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bananas 4 ice cream  pie</td>\n",
       "      <td>70971</td>\n",
       "      <td>180</td>\n",
       "      <td>102353</td>\n",
       "      <td>2003-09-10</td>\n",
       "      <td>[weeknight, time-to-make, course, main-ingredi...</td>\n",
       "      <td>[4270.8, 254.0, 1306.0, 111.0, 127.0, 431.0, 2...</td>\n",
       "      <td>8</td>\n",
       "      <td>['crumble cookies into a 9-inch pie plate , or...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['chocolate sandwich style cookies', 'chocolat...</td>\n",
       "      <td>6</td>\n",
       "      <td>52942</td>\n",
       "      <td>41507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>beat this  banana bread</td>\n",
       "      <td>75452</td>\n",
       "      <td>70</td>\n",
       "      <td>15892</td>\n",
       "      <td>2003-11-04</td>\n",
       "      <td>[weeknight, time-to-make, course, main-ingredi...</td>\n",
       "      <td>[2669.3, 160.0, 976.0, 107.0, 62.0, 310.0, 138.0]</td>\n",
       "      <td>12</td>\n",
       "      <td>['preheat oven to 350 degrees', 'butter two 9x...</td>\n",
       "      <td>from ann hodgman's</td>\n",
       "      <td>['sugar', 'unsalted butter', 'bananas', 'eggs'...</td>\n",
       "      <td>9</td>\n",
       "      <td>7784</td>\n",
       "      <td>44033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cream  of spinach soup</td>\n",
       "      <td>76808</td>\n",
       "      <td>45</td>\n",
       "      <td>95743</td>\n",
       "      <td>2003-11-17</td>\n",
       "      <td>[60-minutes-or-less, time-to-make, course, mai...</td>\n",
       "      <td>[126.0, 11.0, 2.0, 14.0, 5.0, 23.0, 4.0]</td>\n",
       "      <td>9</td>\n",
       "      <td>['bring water and salt to a boil', 'cut the po...</td>\n",
       "      <td>wonderful comfort food from rozanne gold, a fa...</td>\n",
       "      <td>['water', 'salt', 'boiling potatoes', 'fresh s...</td>\n",
       "      <td>8</td>\n",
       "      <td>49580</td>\n",
       "      <td>44795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>crispy crunchy  chicken</td>\n",
       "      <td>83873</td>\n",
       "      <td>35</td>\n",
       "      <td>108291</td>\n",
       "      <td>2004-02-13</td>\n",
       "      <td>[60-minutes-or-less, time-to-make, course, pre...</td>\n",
       "      <td>[335.8, 11.0, 2.0, 24.0, 64.0, 10.0, 10.0]</td>\n",
       "      <td>8</td>\n",
       "      <td>['combine soup , egg and seasoned salt in a bo...</td>\n",
       "      <td>delicious, crunchy fried chicken. this recipe ...</td>\n",
       "      <td>['boneless skinless chicken breast halves', 'c...</td>\n",
       "      <td>10</td>\n",
       "      <td>56008</td>\n",
       "      <td>48779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>boat house  collard greens</td>\n",
       "      <td>107517</td>\n",
       "      <td>525</td>\n",
       "      <td>137696</td>\n",
       "      <td>2005-01-03</td>\n",
       "      <td>[time-to-make, main-ingredient, preparation, v...</td>\n",
       "      <td>[315.8, 0.0, 202.0, 9.0, 6.0, 0.0, 21.0]</td>\n",
       "      <td>7</td>\n",
       "      <td>['put prepared greens in large pot', 'add wate...</td>\n",
       "      <td>my boss gave me this recipe several years ago....</td>\n",
       "      <td>['collard greens', 'brown sugar', 'molasses', ...</td>\n",
       "      <td>7</td>\n",
       "      <td>70460</td>\n",
       "      <td>63258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>deep fried dessert thingys</td>\n",
       "      <td>107699</td>\n",
       "      <td>20</td>\n",
       "      <td>158966</td>\n",
       "      <td>2005-01-05</td>\n",
       "      <td>[30-minutes-or-less, time-to-make, course, pre...</td>\n",
       "      <td>[1663.3, 221.0, 168.0, 66.0, 19.0, 158.0, 29.0]</td>\n",
       "      <td>20</td>\n",
       "      <td>['in a large bowl , mix flour , granulated sug...</td>\n",
       "      <td>my mother used to make this for us as a specia...</td>\n",
       "      <td>['all-purpose flour', 'granulated sugar', 'bak...</td>\n",
       "      <td>13</td>\n",
       "      <td>80474</td>\n",
       "      <td>63374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>berry  good sandwich spread</td>\n",
       "      <td>109439</td>\n",
       "      <td>5</td>\n",
       "      <td>49168</td>\n",
       "      <td>2005-01-25</td>\n",
       "      <td>[15-minutes-or-less, time-to-make, course, pre...</td>\n",
       "      <td>[79.2, 3.0, 58.0, 0.0, 0.0, 6.0, 5.0]</td>\n",
       "      <td>2</td>\n",
       "      <td>['in medium size bowl , coarsely mash cranberr...</td>\n",
       "      <td>horseradish is one of my favorite condiments a...</td>\n",
       "      <td>['whole berry cranberry sauce', 'sour cream', ...</td>\n",
       "      <td>3</td>\n",
       "      <td>25215</td>\n",
       "      <td>64415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all in the kitchen  chili</td>\n",
       "      <td>112140</td>\n",
       "      <td>130</td>\n",
       "      <td>196586</td>\n",
       "      <td>2005-02-25</td>\n",
       "      <td>[time-to-make, course, preparation, main-dish,...</td>\n",
       "      <td>[269.8, 22.0, 32.0, 48.0, 39.0, 27.0, 5.0]</td>\n",
       "      <td>6</td>\n",
       "      <td>['brown ground beef in large pot', 'add choppe...</td>\n",
       "      <td>this modified version of 'mom's' chili was a h...</td>\n",
       "      <td>['ground beef', 'yellow onions', 'diced tomato...</td>\n",
       "      <td>13</td>\n",
       "      <td>99009</td>\n",
       "      <td>66030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arriba   baked winter squash mexican style</td>\n",
       "      <td>137739</td>\n",
       "      <td>55</td>\n",
       "      <td>47892</td>\n",
       "      <td>2005-09-16</td>\n",
       "      <td>[60-minutes-or-less, time-to-make, course, mai...</td>\n",
       "      <td>[51.5, 0.0, 13.0, 0.0, 2.0, 0.0, 4.0]</td>\n",
       "      <td>11</td>\n",
       "      <td>['make a choice and proceed with recipe', 'dep...</td>\n",
       "      <td>autumn is my favorite time of year to cook! th...</td>\n",
       "      <td>['winter squash', 'mexican seasoning', 'mixed ...</td>\n",
       "      <td>7</td>\n",
       "      <td>24590</td>\n",
       "      <td>80434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          name  recipe_id  minutes  user_id  \\\n",
       "5                      apple a day  milk shake       5289        0     1533   \n",
       "18                          chinese  chop suey       8559       70     4481   \n",
       "19           cream  of cauliflower soup  vegan      23850      110     3288   \n",
       "17                              chinese  candy      23933       15    35268   \n",
       "21               cream  of spinach soup  vegan      24701       55     3288   \n",
       "6                        aww  marinated olives      25274       15    21730   \n",
       "1             a bit different  breakfast pizza      31490       30    26278   \n",
       "28                             fried  potatoes      37073       40     1533   \n",
       "14                     calm your nerves  tonic      39959        5    37449   \n",
       "11               better than sex  strawberries      42198     1460    41531   \n",
       "16                              chile rellenos      43026       45    52268   \n",
       "4           amish  tomato ketchup  for canning      44061      190    41706   \n",
       "29       george s at the cove  black bean soup      44123       90    35193   \n",
       "27                       forgotten  minestrone      47366      495    31871   \n",
       "25            emotional balance  spice mixture      48156       10     6164   \n",
       "24             easiest ever  hollandaise sauce      49262       25    64428   \n",
       "26                 fool the meat eaters  chili      54272       40    40525   \n",
       "3                           alouette  potatoes      59389       45    68585   \n",
       "15            chicken lickin  good  pork chops      63986      500    14664   \n",
       "12             better then bush s  baked beans      67547     2970    85627   \n",
       "7               backyard style  barbecued ribs      67888      120    10404   \n",
       "8                     bananas 4 ice cream  pie      70971      180   102353   \n",
       "9                      beat this  banana bread      75452       70    15892   \n",
       "20                      cream  of spinach soup      76808       45    95743   \n",
       "22                     crispy crunchy  chicken      83873       35   108291   \n",
       "13                  boat house  collard greens     107517      525   137696   \n",
       "23                  deep fried dessert thingys     107699       20   158966   \n",
       "10                 berry  good sandwich spread     109439        5    49168   \n",
       "2                    all in the kitchen  chili     112140      130   196586   \n",
       "0   arriba   baked winter squash mexican style     137739       55    47892   \n",
       "\n",
       "     submitted                                               tags  \\\n",
       "5   1999-12-06  [15-minutes-or-less, time-to-make, course, mai...   \n",
       "18  2001-01-27  [weeknight, time-to-make, course, main-ingredi...   \n",
       "19  2002-03-28  [lactose, weeknight, time-to-make, course, mai...   \n",
       "17  2002-03-29  [15-minutes-or-less, time-to-make, course, pre...   \n",
       "21  2002-04-08  [60-minutes-or-less, time-to-make, course, mai...   \n",
       "6   2002-04-14  [15-minutes-or-less, time-to-make, course, mai...   \n",
       "1   2002-06-17  [30-minutes-or-less, time-to-make, course, mai...   \n",
       "28  2002-08-13  [60-minutes-or-less, time-to-make, course, mai...   \n",
       "14  2002-09-10  [15-minutes-or-less, time-to-make, preparation...   \n",
       "11  2002-10-03  [weeknight, time-to-make, course, main-ingredi...   \n",
       "16  2002-10-14  [60-minutes-or-less, time-to-make, course, mai...   \n",
       "4   2002-10-25  [weeknight, time-to-make, course, main-ingredi...   \n",
       "29  2002-10-25  [weeknight, time-to-make, course, main-ingredi...   \n",
       "27  2002-11-21  [weeknight, time-to-make, course, main-ingredi...   \n",
       "25  2002-12-09  [15-minutes-or-less, time-to-make, course, cui...   \n",
       "24  2002-12-19  [30-minutes-or-less, time-to-make, course, mai...   \n",
       "26  2003-02-17  [60-minutes-or-less, time-to-make, course, mai...   \n",
       "3   2003-04-14  [60-minutes-or-less, time-to-make, course, mai...   \n",
       "15  2003-06-06  [weeknight, time-to-make, course, main-ingredi...   \n",
       "12  2003-07-26  [weeknight, time-to-make, course, main-ingredi...   \n",
       "7   2003-07-30  [weeknight, time-to-make, course, main-ingredi...   \n",
       "8   2003-09-10  [weeknight, time-to-make, course, main-ingredi...   \n",
       "9   2003-11-04  [weeknight, time-to-make, course, main-ingredi...   \n",
       "20  2003-11-17  [60-minutes-or-less, time-to-make, course, mai...   \n",
       "22  2004-02-13  [60-minutes-or-less, time-to-make, course, pre...   \n",
       "13  2005-01-03  [time-to-make, main-ingredient, preparation, v...   \n",
       "23  2005-01-05  [30-minutes-or-less, time-to-make, course, pre...   \n",
       "10  2005-01-25  [15-minutes-or-less, time-to-make, course, pre...   \n",
       "2   2005-02-25  [time-to-make, course, preparation, main-dish,...   \n",
       "0   2005-09-16  [60-minutes-or-less, time-to-make, course, mai...   \n",
       "\n",
       "                                            nutrition  n_steps  \\\n",
       "5            [160.2, 10.0, 55.0, 3.0, 9.0, 20.0, 7.0]        4   \n",
       "18         [395.4, 31.0, 20.0, 29.0, 51.0, 33.0, 8.0]        8   \n",
       "19           [174.2, 4.0, 24.0, 1.0, 15.0, 1.0, 10.0]       10   \n",
       "17           [232.7, 21.0, 77.0, 4.0, 6.0, 38.0, 8.0]        4   \n",
       "21             [64.8, 3.0, 13.0, 54.0, 4.0, 2.0, 3.0]       10   \n",
       "6            [380.7, 53.0, 7.0, 24.0, 6.0, 24.0, 6.0]        4   \n",
       "1           [173.4, 18.0, 0.0, 17.0, 22.0, 35.0, 1.0]        9   \n",
       "28              [132.6, 8.0, 4.0, 3.0, 4.0, 5.0, 6.0]       14   \n",
       "14                [8.2, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]        6   \n",
       "11      [734.1, 66.0, 199.0, 10.0, 10.0, 117.0, 28.0]        8   \n",
       "16           [94.0, 10.0, 0.0, 11.0, 11.0, 21.0, 0.0]        9   \n",
       "4           [352.9, 1.0, 337.0, 23.0, 3.0, 0.0, 28.0]        5   \n",
       "29      [804.7, 108.0, 26.0, 19.0, 28.0, 214.0, 10.0]       11   \n",
       "27        [346.9, 24.0, 18.0, 42.0, 42.0, 30.0, 10.0]        5   \n",
       "25           [182.7, 11.0, 4.0, 1.0, 13.0, 4.0, 10.0]        2   \n",
       "24       [1290.4, 213.0, 4.0, 53.0, 22.0, 417.0, 1.0]        7   \n",
       "26          [295.6, 3.0, 56.0, 76.0, 32.0, 1.0, 18.0]        9   \n",
       "3           [368.1, 17.0, 10.0, 2.0, 14.0, 8.0, 20.0]       11   \n",
       "15             [105.7, 8.0, 0.0, 26.0, 5.0, 4.0, 3.0]        5   \n",
       "12       [462.4, 28.0, 214.0, 69.0, 14.0, 29.0, 23.0]        9   \n",
       "7      [1109.5, 83.0, 378.0, 275.0, 96.0, 86.0, 36.0]       10   \n",
       "8   [4270.8, 254.0, 1306.0, 111.0, 127.0, 431.0, 2...        8   \n",
       "9   [2669.3, 160.0, 976.0, 107.0, 62.0, 310.0, 138.0]       12   \n",
       "20           [126.0, 11.0, 2.0, 14.0, 5.0, 23.0, 4.0]        9   \n",
       "22         [335.8, 11.0, 2.0, 24.0, 64.0, 10.0, 10.0]        8   \n",
       "13           [315.8, 0.0, 202.0, 9.0, 6.0, 0.0, 21.0]        7   \n",
       "23    [1663.3, 221.0, 168.0, 66.0, 19.0, 158.0, 29.0]       20   \n",
       "10              [79.2, 3.0, 58.0, 0.0, 0.0, 6.0, 5.0]        2   \n",
       "2          [269.8, 22.0, 32.0, 48.0, 39.0, 27.0, 5.0]        6   \n",
       "0               [51.5, 0.0, 13.0, 0.0, 2.0, 0.0, 4.0]       11   \n",
       "\n",
       "                                                steps  \\\n",
       "5   ['combine ingredients in blender', 'cover and ...   \n",
       "18  ['brown ground meat and onion in a large pot',...   \n",
       "19  ['heat the oil or margarine in a soup pot and ...   \n",
       "17  ['melt butterscotch chips in heavy saucepan ov...   \n",
       "21  ['in a 3 qt saucepan over medium high heat , s...   \n",
       "6   ['toast the fennel seeds and lightly crush the...   \n",
       "1   ['preheat oven to 425 degrees f', 'press dough...   \n",
       "28  ['preheat oven to 400 degrees', 'cut the potat...   \n",
       "14  ['combine herbs', 'dosage: one-half teaspoonfu...   \n",
       "11  ['crush vanilla wafers into fine crumbs and li...   \n",
       "16  ['drain green chiles', 'sprinkle cornstarch on...   \n",
       "4   ['mix all ingredients& boil for 2 1 / 2 hours ...   \n",
       "29  ['in 1 / 4 cup butter , saute carrots , onion ...   \n",
       "27  ['in a slow cooker , combine the first nine in...   \n",
       "25  ['mix the spices together and store in an airt...   \n",
       "24  ['cut the butter into several pieces and bring...   \n",
       "26  ['rehydrate tvp if needed', 'spray or oil a la...   \n",
       "3   ['place potatoes in a large pot of lightly sal...   \n",
       "15  ['dredge pork chops in mixture of flour , salt...   \n",
       "12  ['in a very large sauce pan cover the beans an...   \n",
       "7   ['in a medium saucepan combine all the ingredi...   \n",
       "8   ['crumble cookies into a 9-inch pie plate , or...   \n",
       "9   ['preheat oven to 350 degrees', 'butter two 9x...   \n",
       "20  ['bring water and salt to a boil', 'cut the po...   \n",
       "22  ['combine soup , egg and seasoned salt in a bo...   \n",
       "13  ['put prepared greens in large pot', 'add wate...   \n",
       "23  ['in a large bowl , mix flour , granulated sug...   \n",
       "10  ['in medium size bowl , coarsely mash cranberr...   \n",
       "2   ['brown ground beef in large pot', 'add choppe...   \n",
       "0   ['make a choice and proceed with recipe', 'dep...   \n",
       "\n",
       "                                          description  \\\n",
       "5                                                 NaN   \n",
       "18                              easy one-pot dinner.    \n",
       "19                              this is a dairy free    \n",
       "17  a little different, and oh so good. i include ...   \n",
       "21  thickened with a mix of cooked oats and vegies...   \n",
       "6   my italian mil was thoroughly impressed by my ...   \n",
       "1   this recipe calls for the crust to be prebaked...   \n",
       "28  my husband made these up last week, very tasty...   \n",
       "14  this will prove a blessing to everyone who tak...   \n",
       "11  simple but sexy. this was in my local newspape...   \n",
       "16  a favorite from a local restaurant no longer i...   \n",
       "4   my dh's amish mother raised him on this recipe...   \n",
       "29  an original recipe created by chef scott meska...   \n",
       "27                           this recipe came from a    \n",
       "25  really an effective spice blend...i got it in ...   \n",
       "24  the secret to this easy hollandaise sauce is i...   \n",
       "26  this recipe was adapted by my mother and mysel...   \n",
       "3   this is a super easy, great tasting, make ahea...   \n",
       "15  here's and old standby i enjoy from time to ti...   \n",
       "12  i'd have to say that this is a labor of love d...   \n",
       "7   this recipe is posted by request and was origi...   \n",
       "8                                                 NaN   \n",
       "9                                 from ann hodgman's    \n",
       "20  wonderful comfort food from rozanne gold, a fa...   \n",
       "22  delicious, crunchy fried chicken. this recipe ...   \n",
       "13  my boss gave me this recipe several years ago....   \n",
       "23  my mother used to make this for us as a specia...   \n",
       "10  horseradish is one of my favorite condiments a...   \n",
       "2   this modified version of 'mom's' chili was a h...   \n",
       "0   autumn is my favorite time of year to cook! th...   \n",
       "\n",
       "                                          ingredients  n_ingredients  \\\n",
       "5   ['milk', 'vanilla ice cream', 'frozen apple ju...              4   \n",
       "18  ['celery', 'onion', 'ground pork', 'soy sauce'...              7   \n",
       "19  ['canola oil', 'onion', 'garlic', 'cauliflower...             16   \n",
       "17  ['butterscotch chips', 'chinese noodles', 'sal...              3   \n",
       "21  ['onion', 'scallion', 'apple juice', 'olive oi...             12   \n",
       "6   ['fennel seeds', 'green olives', 'ripe olives'...              9   \n",
       "1   ['prepared pizza crust', 'sausage patty', 'egg...              6   \n",
       "28          ['red potatoes', 'margarine', 'rosemary']              3   \n",
       "14  ['gentian root', 'scullcap herb', 'burnet root...              5   \n",
       "11  ['vanilla wafers', 'butter', 'powdered sugar',...              7   \n",
       "16  ['egg roll wrap', 'whole green chilies', 'chee...              5   \n",
       "4   ['tomato juice', 'apple cider vinegar', 'sugar...              8   \n",
       "29  ['unsalted butter', 'carrot', 'onion', 'celery...             18   \n",
       "27  ['beef stew meat', 'water', 'tomatoes', 'beef ...             14   \n",
       "25  ['ground black pepper', 'ground ginger', 'grou...              6   \n",
       "24  ['butter', 'lemon, juice of', 'salt', 'white p...              5   \n",
       "26  ['vegetarian ground beef', 'garlic', 'onion', ...             12   \n",
       "3   ['spreadable cheese with garlic and herbs', 'n...             11   \n",
       "15  ['lean pork chops', 'flour', 'salt', 'dry must...              7   \n",
       "12  ['great northern bean', 'chicken bouillon cube...             13   \n",
       "7   ['pork spareribs', 'soy sauce', 'fresh garlic'...             22   \n",
       "8   ['chocolate sandwich style cookies', 'chocolat...              6   \n",
       "9   ['sugar', 'unsalted butter', 'bananas', 'eggs'...              9   \n",
       "20  ['water', 'salt', 'boiling potatoes', 'fresh s...              8   \n",
       "22  ['boneless skinless chicken breast halves', 'c...             10   \n",
       "13  ['collard greens', 'brown sugar', 'molasses', ...              7   \n",
       "23  ['all-purpose flour', 'granulated sugar', 'bak...             13   \n",
       "10  ['whole berry cranberry sauce', 'sour cream', ...              3   \n",
       "2   ['ground beef', 'yellow onions', 'diced tomato...             13   \n",
       "0   ['winter squash', 'mexican seasoning', 'mixed ...              7   \n",
       "\n",
       "    user_id_contig  recipe_id_contig  \n",
       "5              553              2239  \n",
       "18            2248              3577  \n",
       "19            1601             13093  \n",
       "17           17631             13140  \n",
       "21            1601             13613  \n",
       "6            10577             13966  \n",
       "1            12889             17776  \n",
       "28             553             21164  \n",
       "14           18871             22936  \n",
       "11           21277             24281  \n",
       "16           27025             24774  \n",
       "4            21377             25380  \n",
       "29           17590             25418  \n",
       "27           15939             27220  \n",
       "25            3119             27690  \n",
       "24           33908             28331  \n",
       "26           20702             31396  \n",
       "3            36138             34527  \n",
       "15            7197             37390  \n",
       "12           44416             39549  \n",
       "7             5177             39735  \n",
       "8            52942             41507  \n",
       "9             7784             44033  \n",
       "20           49580             44795  \n",
       "22           56008             48779  \n",
       "13           70460             63258  \n",
       "23           80474             63374  \n",
       "10           25215             64415  \n",
       "2            99009             66030  \n",
       "0            24590             80434  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# order recipes by id, we'll be assigning these features in the order of graph creation\n",
    "recipes[:30].sort_values(by=['recipe_id_contig'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-01 19:04:46,371: \n",
      "2021-12-01 19:04:46,372: \n",
      "2021-12-01 19:04:46,388: \n",
      "2021-12-01 19:04:46,402: \n",
      "2021-12-01 19:04:46,416: \n",
      "2021-12-01 19:04:46,429: \n",
      "2021-12-01 19:04:46,441: \n",
      "2021-12-01 19:04:46,453: \n",
      "2021-12-01 19:04:46,466: \n",
      "2021-12-01 19:04:46,478: \n",
      "2021-12-01 19:04:46,490: \n",
      "2021-12-01 19:04:46,502: \n",
      "2021-12-01 19:04:46,515: \n",
      "2021-12-01 19:04:46,527: \n",
      "2021-12-01 19:04:46,539: \n",
      "2021-12-01 19:04:46,551: \n",
      "2021-12-01 19:04:46,565: \n",
      "2021-12-01 19:04:46,577: \n",
      "2021-12-01 19:04:46,589: \n",
      "2021-12-01 19:04:46,601: \n",
      "2021-12-01 19:04:46,614: \n",
      "2021-12-01 19:04:46,626: \n",
      "2021-12-01 19:04:46,638: \n",
      "2021-12-01 19:04:46,651: \n",
      "2021-12-01 19:04:46,663: \n",
      "2021-12-01 19:04:46,671: \n",
      "2021-12-01 19:04:46,672: \n",
      "2021-12-01 19:04:46,752: \n",
      "2021-12-01 19:04:46,752: \n",
      "2021-12-01 19:04:46,860: \n",
      "2021-12-01 19:04:46,861: \n",
      "2021-12-01 19:04:46,862: \n",
      "2021-12-01 19:04:47,062: \n",
      "2021-12-01 19:04:47,062: \n",
      "2021-12-01 19:04:47,081: \n",
      "2021-12-01 19:04:48,442: \n",
      "2021-12-01 19:04:49,750: \n",
      "2021-12-01 19:04:50,889: \n",
      "2021-12-01 19:04:52,097: \n",
      "2021-12-01 19:04:53,332: \n",
      "2021-12-01 19:04:54,594: \n",
      "2021-12-01 19:04:55,663: \n",
      "2021-12-01 19:04:56,812: \n",
      "2021-12-01 19:04:56,929: \n",
      "2021-12-01 19:04:56,940: \n",
      "2021-12-01 19:04:57,025: \n",
      "2021-12-01 19:04:57,033: \n",
      "2021-12-01 19:04:57,034: \n",
      "2021-12-01 19:04:58,405: \n",
      "2021-12-01 19:04:59,640: \n",
      "2021-12-01 19:05:00,924: \n",
      "2021-12-01 19:05:02,205: \n",
      "2021-12-01 19:05:03,445: \n",
      "2021-12-01 19:05:04,635: \n",
      "2021-12-01 19:05:05,842: \n",
      "2021-12-01 19:05:07,021: \n",
      "2021-12-01 19:05:07,076: \n",
      "2021-12-01 19:05:07,081: \n",
      "2021-12-01 19:05:07,194: \n",
      "2021-12-01 19:05:07,198: \n",
      "2021-12-01 19:05:07,199: \n",
      "2021-12-01 19:05:08,543: \n",
      "2021-12-01 19:05:09,837: \n",
      "2021-12-01 19:05:11,094: \n",
      "2021-12-01 19:05:12,333: \n",
      "2021-12-01 19:05:13,578: \n",
      "2021-12-01 19:05:14,779: \n",
      "2021-12-01 19:05:15,969: \n",
      "2021-12-01 19:05:17,138: \n",
      "2021-12-01 19:05:17,179: \n",
      "2021-12-01 19:05:17,205: \n",
      "2021-12-01 19:05:17,305: \n",
      "2021-12-01 19:05:17,306: \n",
      "2021-12-01 19:05:17,306: \n",
      "2021-12-01 19:05:18,686: \n",
      "2021-12-01 19:05:19,942: \n",
      "2021-12-01 19:05:21,202: \n",
      "2021-12-01 19:05:22,466: \n",
      "2021-12-01 19:05:23,635: \n",
      "2021-12-01 19:05:24,676: \n",
      "2021-12-01 19:05:25,752: \n",
      "2021-12-01 19:05:26,848: \n",
      "2021-12-01 19:05:26,897: \n",
      "2021-12-01 19:05:26,933: \n",
      "2021-12-01 19:05:27,021: \n",
      "2021-12-01 19:05:27,023: \n",
      "2021-12-01 19:05:27,023: \n",
      "2021-12-01 19:05:28,421: \n",
      "2021-12-01 19:05:29,699: \n",
      "2021-12-01 19:05:30,902: \n",
      "2021-12-01 19:05:32,061: \n",
      "2021-12-01 19:05:33,192: \n",
      "2021-12-01 19:05:34,362: \n",
      "2021-12-01 19:05:35,609: \n",
      "2021-12-01 19:05:36,799: \n",
      "2021-12-01 19:05:36,870: \n",
      "2021-12-01 19:05:36,873: \n",
      "2021-12-01 19:05:36,983: \n",
      "2021-12-01 19:05:36,987: \n",
      "2021-12-01 19:05:36,987: \n",
      "2021-12-01 19:05:38,330: \n",
      "2021-12-01 19:05:39,602: \n",
      "2021-12-01 19:05:40,875: \n",
      "2021-12-01 19:05:42,181: \n",
      "2021-12-01 19:05:43,368: \n",
      "2021-12-01 19:05:44,601: \n",
      "2021-12-01 19:05:45,772: \n",
      "2021-12-01 19:05:46,887: \n",
      "2021-12-01 19:05:46,963: \n",
      "2021-12-01 19:05:46,969: \n",
      "2021-12-01 19:05:47,071: \n",
      "2021-12-01 19:05:47,079: \n",
      "2021-12-01 19:05:47,079: \n",
      "2021-12-01 19:05:48,485: \n",
      "2021-12-01 19:05:49,747: \n",
      "2021-12-01 19:05:51,038: \n",
      "2021-12-01 19:05:52,276: \n",
      "2021-12-01 19:05:53,490: \n",
      "2021-12-01 19:05:54,704: \n",
      "2021-12-01 19:05:55,923: \n",
      "2021-12-01 19:05:57,000: \n",
      "2021-12-01 19:05:57,061: \n",
      "2021-12-01 19:05:57,065: \n",
      "2021-12-01 19:05:57,175: \n",
      "2021-12-01 19:05:57,178: \n",
      "2021-12-01 19:05:57,179: \n",
      "2021-12-01 19:05:58,582: \n",
      "2021-12-01 19:05:59,841: \n",
      "2021-12-01 19:06:01,128: \n",
      "2021-12-01 19:06:02,367: \n",
      "2021-12-01 19:06:03,487: \n",
      "2021-12-01 19:06:04,693: \n",
      "2021-12-01 19:06:05,905: \n",
      "2021-12-01 19:06:07,084: \n",
      "2021-12-01 19:06:07,150: \n",
      "2021-12-01 19:06:07,166: \n",
      "2021-12-01 19:06:07,266: \n",
      "2021-12-01 19:06:07,275: \n",
      "2021-12-01 19:06:07,275: \n",
      "2021-12-01 19:06:08,522: \n",
      "2021-12-01 19:06:09,720: \n",
      "2021-12-01 19:06:11,057: \n",
      "2021-12-01 19:06:12,353: \n",
      "2021-12-01 19:06:13,592: \n",
      "2021-12-01 19:06:14,782: \n",
      "2021-12-01 19:06:16,018: \n",
      "2021-12-01 19:06:17,152: \n",
      "2021-12-01 19:06:17,209: \n",
      "2021-12-01 19:06:17,217: \n",
      "2021-12-01 19:06:17,321: \n",
      "2021-12-01 19:06:17,324: \n",
      "2021-12-01 19:06:17,325: \n",
      "2021-12-01 19:06:18,639: \n",
      "2021-12-01 19:06:20,020: \n",
      "2021-12-01 19:06:21,258: \n",
      "2021-12-01 19:06:22,468: \n",
      "2021-12-01 19:06:23,714: \n",
      "2021-12-01 19:06:25,003: \n",
      "2021-12-01 19:06:26,229: \n",
      "2021-12-01 19:06:27,413: \n",
      "2021-12-01 19:06:27,495: \n",
      "2021-12-01 19:06:27,498: \n",
      "2021-12-01 19:06:27,593: \n",
      "2021-12-01 19:06:27,602: \n",
      "2021-12-01 19:06:27,602: \n",
      "2021-12-01 19:06:27,603: \n",
      "2021-12-01 19:06:27,603: \n"
     ]
    }
   ],
   "source": [
    "''' Name representation: We're using doc2vec '''\n",
    "name_documents = [TaggedDocument(simple_preprocess(str(row[1]['name'])),\n",
    "                                 [row[1]['recipe_id_contig']])\n",
    "                  for row in recipes.sort_values(by=['recipe_id_contig']).iterrows()]\n",
    "name_model = Doc2Vec(name_documents, vector_size=20, window=2, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([137739,  31490, 112140,  ..., 308080, 298512, 298509],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_model.dv[33]\n",
    "name_model.dv.get_vector(33)\n",
    "\n",
    "# get tensor of recipe ids\n",
    "torch.Tensor(recipes.recipe_id.values).int()\n",
    "\n",
    "# get tensor of name vectors\n",
    "#name_model.dv.get_vector(330)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name_documents\n",
    "name_model.dv.get_vector(199190)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_id_to_contig_map[recipes_df.head(2).recipe_id.iloc[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.from_numpy(name_model.dv.vectors[0])\n",
    "hg.etypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User vertex features: \n",
    "The options here could be:\n",
    "1. The reviews users left for recipes\n",
    "2. Trainable embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Features for users '''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge features: user review and rating\n",
    "\n",
    "Assign each user's rating (as a `torch.Tensor([<rating_value>]`) of a recipe to the edge connecting them with that recipe \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(interactions.user_id.unique()))\n",
    "# interactions.head(4)\n",
    "# review_df.head(4)\n",
    "# experimenting to get it right. But this is what we send to the esdge\n",
    "torch.from_numpy(review_df.rating.to_numpy().reshape(-1, 1), device=cuda).to(cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([45472, 45472, 45472,  ..., 25579, 23488, 23488])\n",
      "tensor([23488, 23488, 25579,  ..., 45472, 45472, 45472])\n"
     ]
    }
   ],
   "source": [
    "print(torch.flip(torch.LongTensor(interactions.recipe_id_contig.values), dims=[0]))\n",
    "print(torch.LongTensor(interactions.recipe_id_contig.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort interactions by recipe id\n",
    "interactions = interactions.sort_values(by=['user_id_contig'])\n",
    "\n",
    "# sort recipes by user_id\n",
    "recipes = recipes.sort_values(by=['recipe_id_contig'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes={'recipe': 231637, 'user': 236568},\n",
       "      num_edges={('recipe', 'isRated', 'user'): 1132198, ('user', 'rated', 'recipe'): 1132198},\n",
       "      metagraph=[('recipe', 'user', 'isRated'), ('user', 'recipe', 'rated')])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Try to build a (heterogeneous) graph, use the \n",
    "    columns with sorted contigous IDs for recipes and user IDs \n",
    "\"\"\"\n",
    "hg = dgl.heterograph({\n",
    "#     ('user', 'reviewed', 'recipe'): (torch.LongTensor(interactions.user_id_contig.values),\n",
    "#                                      torch.LongTensor(interactions.recipe_id_contig.values)),\n",
    "#     ('recipe', 'wasReviewedBy', 'user'): (torch.flip(torch.LongTensor(interactions.recipe_id_contig.values), dims=[0]),\n",
    "#                                           torch.flip(torch.LongTensor(interactions.user_id_contig.values), dims=[0])),\n",
    "#     ('user', 'submitted', 'recipe'): (torch.LongTensor(recipes.user_id_contig.values),\n",
    "#                                       torch.LongTensor(recipes.recipe_id_contig.values)),\n",
    "    ('user', 'rated', 'recipe'): (torch.LongTensor(interactions.user_id_contig.values),\n",
    "                                  torch.LongTensor(interactions.recipe_id_contig.values)),\n",
    "    ('recipe', 'isRated', 'user'): (torch.flip(torch.LongTensor(interactions.recipe_id_contig.values), dims=[0]),\n",
    "                                    torch.flip(torch.LongTensor(interactions.user_id_contig.values), dims=[0])),\n",
    "})  # , device='cuda:0')\n",
    "hg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: also add reverse nodes/relationships for each relationship "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236568"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hg.num_nodes('user') # 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add reversed edge\n",
    "# hgg = hg.add_reverse_edges(copy_edata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set(submitted_df.user_id.values).difference(set(review_df.user_id.values))))\n",
    "len(review_df.recipe_id.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign features associated with the nodes and edges. \n",
    "These features (at this time) include: <br>\n",
    "1. Recipe name ( as doc2vec embeddings ) \n",
    "2. Rating (user -> recipe (reviewed) edge) <br>\n",
    "\n",
    "#### TBD:\n",
    "3. Description (recipe) <br>\n",
    "4. Ingredients (recipe) <br>\n",
    "5. Steps <br>\n",
    "6. calorie level <br>\n",
    "7. Review (user -> recipe (reviewed) edge) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign name features \n",
    "hg.ndata['name'] = {'recipe': torch.from_numpy(name_model.dv.vectors).float()}  # .to('cuda:0')}\n",
    "# hg.nodes['recipe'].data['name'][torch.Tensor(recipes.recipe_id.values).int()] = torch.from_numpy(name_model.dv.vectors).float().to(hg.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<class 'dict'>, {'name': {'recipe': tensor([[-0.2057, -0.0272, -0.0763,  ...,  0.0300, -0.1241,  0.1883],\n",
       "        [ 0.0272, -0.0428, -0.0711,  ..., -0.0867,  0.0113,  0.0484],\n",
       "        [-0.1144,  0.0363,  0.1403,  ..., -0.0060, -0.0717, -0.0547],\n",
       "        ...,\n",
       "        [ 0.0390, -0.0190,  0.0812,  ..., -0.0467, -0.0260,  0.0459],\n",
       "        [ 0.0142,  0.1425, -0.0207,  ..., -0.0095,  0.0040, -0.0791],\n",
       "        [-0.0166,  0.0559, -0.0348,  ..., -0.0575,  0.0448, -0.0595]])}})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hg.ndata\n",
    "\n",
    "# torch.from_numpy(name_model.dv.vectors).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' assign rating features to reviewed edge'''\n",
    "# hg.edata['rating'] = {'reviewed' : torch.from_numpy(review_df.rating.to_numpy().reshape(-1, 1)).to(hg.device)}\n",
    "hg.edata['rating'] = {'rated': torch.LongTensor(interactions.rating.values)}  # .to('cuda:0')}\n",
    "hg.edata['rating'] = {'isRated': torch.flip(torch.LongTensor(interactions.rating.values), dims=[0])}  # .to('cuda:0')}\n",
    "# FIXME: ratings will be different edge types  not edge features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('recipe', 'isRated', 'user'): tensor([5, 5, 5,  ..., 5, 5, 5]),\n",
       " ('user', 'rated', 'recipe'): tensor([5, 5, 5,  ..., 5, 5, 5])}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hg.edata['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hg.num_edges('reviewed')\n",
    "torch.zeros(5, dtype=torch.bool).bernoulli(0.7).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Randomly generate masks training masks on recipe \n",
    "    and user nodes and reviewed edges \n",
    "'''\n",
    "hg.nodes['user'].data['train_mask'] = torch.zeros(hg.num_nodes('user'),\n",
    "                                                  dtype=torch.bool).bernoulli(0.7).to(hg.device)\n",
    "hg.nodes['recipe'].data['train_mask'] = torch.zeros(hg.num_nodes('recipe'),\n",
    "                                                  dtype=torch.bool).bernoulli(0.7).to(hg.device)\n",
    "\n",
    "hg.edges['rated'].data['train_mask'] = torch.zeros(hg.num_edges('rated'),\n",
    "                                                   dtype=torch.bool).bernoulli(0.7).to(hg.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign calories as features to recipes vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ground beef',\n",
       " 'onion',\n",
       " 'diced tomatoes',\n",
       " 'red kidney beans',\n",
       " 'taco seasoning',\n",
       " 'corn',\n",
       " 'green chilies',\n",
       " 'jalapeno',\n",
       " 'ranch dressing',\n",
       " 'bow tie pasta',\n",
       " 'sour cream']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes.ingredients.head(2).iloc[1]\n",
    "# simple_preprocess(\"this is just another sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    We need change ingredient representation from their string form to a \n",
    "    tensor representation. Since ingredients is a list of string tokens,\n",
    "    we can represent the ingredients as a document vector using doc2vec \n",
    "\"\"\"\n",
    "# 1. format ingredients column\n",
    "recipes['ingredients'] = recipes.ingredients.apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-01 19:08:08,710: \n",
      "2021-12-01 19:08:08,710: \n",
      "2021-12-01 19:08:08,742: \n",
      "2021-12-01 19:08:08,769: \n",
      "2021-12-01 19:08:08,794: \n",
      "2021-12-01 19:08:08,819: \n",
      "2021-12-01 19:08:08,843: \n",
      "2021-12-01 19:08:08,868: \n",
      "2021-12-01 19:08:08,892: \n",
      "2021-12-01 19:08:08,917: \n",
      "2021-12-01 19:08:08,942: \n",
      "2021-12-01 19:08:08,967: \n",
      "2021-12-01 19:08:08,992: \n",
      "2021-12-01 19:08:09,020: \n",
      "2021-12-01 19:08:09,045: \n",
      "2021-12-01 19:08:09,070: \n",
      "2021-12-01 19:08:09,093: \n",
      "2021-12-01 19:08:09,119: \n",
      "2021-12-01 19:08:09,143: \n",
      "2021-12-01 19:08:09,168: \n",
      "2021-12-01 19:08:09,192: \n",
      "2021-12-01 19:08:09,217: \n",
      "2021-12-01 19:08:09,243: \n",
      "2021-12-01 19:08:09,268: \n",
      "2021-12-01 19:08:09,296: \n",
      "2021-12-01 19:08:09,306: \n",
      "2021-12-01 19:08:09,306: \n",
      "2021-12-01 19:08:09,343: \n",
      "2021-12-01 19:08:09,345: \n",
      "2021-12-01 19:08:09,404: \n",
      "2021-12-01 19:08:09,405: \n",
      "2021-12-01 19:08:09,405: \n",
      "2021-12-01 19:08:09,515: \n",
      "2021-12-01 19:08:09,515: \n",
      "2021-12-01 19:08:09,597: \n",
      "2021-12-01 19:08:10,631: \n",
      "2021-12-01 19:08:11,641: \n",
      "2021-12-01 19:08:12,660: \n",
      "2021-12-01 19:08:13,675: \n",
      "2021-12-01 19:08:14,751: \n",
      "2021-12-01 19:08:15,766: \n",
      "2021-12-01 19:08:16,818: \n",
      "2021-12-01 19:08:17,853: \n",
      "2021-12-01 19:08:18,870: \n",
      "2021-12-01 19:08:18,969: \n",
      "2021-12-01 19:08:19,018: \n",
      "2021-12-01 19:08:19,027: \n",
      "2021-12-01 19:08:19,031: \n",
      "2021-12-01 19:08:19,032: \n",
      "2021-12-01 19:08:20,168: \n",
      "2021-12-01 19:08:21,242: \n",
      "2021-12-01 19:08:22,321: \n",
      "2021-12-01 19:08:23,323: \n",
      "2021-12-01 19:08:24,403: \n",
      "2021-12-01 19:08:25,463: \n",
      "2021-12-01 19:08:26,473: \n",
      "2021-12-01 19:08:27,529: \n",
      "2021-12-01 19:08:28,226: \n",
      "2021-12-01 19:08:28,264: \n",
      "2021-12-01 19:08:28,293: \n",
      "2021-12-01 19:08:28,294: \n",
      "2021-12-01 19:08:28,294: \n",
      "2021-12-01 19:08:29,325: \n",
      "2021-12-01 19:08:30,357: \n",
      "2021-12-01 19:08:31,444: \n",
      "2021-12-01 19:08:32,473: \n",
      "2021-12-01 19:08:33,504: \n",
      "2021-12-01 19:08:34,517: \n",
      "2021-12-01 19:08:35,531: \n",
      "2021-12-01 19:08:36,534: \n",
      "2021-12-01 19:08:37,604: \n",
      "2021-12-01 19:08:37,621: \n",
      "2021-12-01 19:08:37,651: \n",
      "2021-12-01 19:08:37,691: \n",
      "2021-12-01 19:08:37,695: \n",
      "2021-12-01 19:08:37,696: \n",
      "2021-12-01 19:08:38,851: \n",
      "2021-12-01 19:08:39,953: \n",
      "2021-12-01 19:08:40,967: \n",
      "2021-12-01 19:08:42,001: \n",
      "2021-12-01 19:08:43,103: \n",
      "2021-12-01 19:08:44,191: \n",
      "2021-12-01 19:08:45,196: \n",
      "2021-12-01 19:08:46,197: \n",
      "2021-12-01 19:08:47,281: \n",
      "2021-12-01 19:08:47,286: \n",
      "2021-12-01 19:08:47,320: \n",
      "2021-12-01 19:08:47,352: \n",
      "2021-12-01 19:08:47,366: \n",
      "2021-12-01 19:08:47,366: \n",
      "2021-12-01 19:08:48,388: \n",
      "2021-12-01 19:08:49,473: \n",
      "2021-12-01 19:08:50,574: \n",
      "2021-12-01 19:08:51,575: \n",
      "2021-12-01 19:08:52,623: \n",
      "2021-12-01 19:08:53,682: \n",
      "2021-12-01 19:08:54,783: \n",
      "2021-12-01 19:08:55,874: \n",
      "2021-12-01 19:08:56,954: \n",
      "2021-12-01 19:08:58,010: \n",
      "2021-12-01 19:08:58,058: \n",
      "2021-12-01 19:08:58,063: \n",
      "2021-12-01 19:08:58,088: \n",
      "2021-12-01 19:08:58,094: \n",
      "2021-12-01 19:08:58,095: \n",
      "2021-12-01 19:08:59,259: \n",
      "2021-12-01 19:09:00,371: \n",
      "2021-12-01 19:09:01,389: \n",
      "2021-12-01 19:09:02,539: \n",
      "2021-12-01 19:09:03,558: \n",
      "2021-12-01 19:09:04,570: \n",
      "2021-12-01 19:09:05,599: \n",
      "2021-12-01 19:09:06,632: \n",
      "2021-12-01 19:09:07,643: \n",
      "2021-12-01 19:09:08,549: \n",
      "2021-12-01 19:09:08,570: \n",
      "2021-12-01 19:09:08,604: \n",
      "2021-12-01 19:09:08,616: \n",
      "2021-12-01 19:09:08,617: \n",
      "2021-12-01 19:09:09,749: \n",
      "2021-12-01 19:09:10,907: \n",
      "2021-12-01 19:09:11,924: \n",
      "2021-12-01 19:09:12,970: \n",
      "2021-12-01 19:09:13,970: \n",
      "2021-12-01 19:09:15,028: \n",
      "2021-12-01 19:09:16,052: \n",
      "2021-12-01 19:09:17,138: \n",
      "2021-12-01 19:09:17,462: \n",
      "2021-12-01 19:09:17,490: \n",
      "2021-12-01 19:09:17,516: \n",
      "2021-12-01 19:09:17,530: \n",
      "2021-12-01 19:09:17,530: \n",
      "2021-12-01 19:09:18,584: \n",
      "2021-12-01 19:09:19,592: \n",
      "2021-12-01 19:09:20,604: \n",
      "2021-12-01 19:09:21,664: \n",
      "2021-12-01 19:09:22,670: \n",
      "2021-12-01 19:09:23,674: \n",
      "2021-12-01 19:09:24,733: \n",
      "2021-12-01 19:09:25,751: \n",
      "2021-12-01 19:09:26,261: \n",
      "2021-12-01 19:09:26,295: \n",
      "2021-12-01 19:09:26,326: \n",
      "2021-12-01 19:09:26,328: \n",
      "2021-12-01 19:09:26,329: \n",
      "2021-12-01 19:09:27,412: \n",
      "2021-12-01 19:09:28,429: \n",
      "2021-12-01 19:09:29,458: \n",
      "2021-12-01 19:09:30,478: \n",
      "2021-12-01 19:09:31,488: \n",
      "2021-12-01 19:09:32,562: \n",
      "2021-12-01 19:09:33,569: \n",
      "2021-12-01 19:09:34,578: \n",
      "2021-12-01 19:09:35,223: \n",
      "2021-12-01 19:09:35,232: \n",
      "2021-12-01 19:09:35,277: \n",
      "2021-12-01 19:09:35,278: \n",
      "2021-12-01 19:09:35,279: \n",
      "2021-12-01 19:09:36,343: \n",
      "2021-12-01 19:09:37,357: \n",
      "2021-12-01 19:09:38,381: \n",
      "2021-12-01 19:09:39,401: \n",
      "2021-12-01 19:09:40,517: \n",
      "2021-12-01 19:09:41,518: \n",
      "2021-12-01 19:09:42,549: \n",
      "2021-12-01 19:09:43,593: \n",
      "2021-12-01 19:09:44,221: \n",
      "2021-12-01 19:09:44,225: \n",
      "2021-12-01 19:09:44,270: \n",
      "2021-12-01 19:09:44,283: \n",
      "2021-12-01 19:09:44,283: \n",
      "2021-12-01 19:09:44,284: \n",
      "2021-12-01 19:09:44,284: \n"
     ]
    }
   ],
   "source": [
    "''' 2. Create embeddings for ingredient tokens in every recipe '''\n",
    "\n",
    "token_documents = [TaggedDocument(row[1]['ingredients'],\n",
    "                                  [row[1]['recipe_id_contig']])\n",
    "                  for row in recipes.sort_values(by=['recipe_id_contig']).iterrows()]\n",
    "token_model = Doc2Vec(token_documents, vector_size=70, window=2, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 3. Assign ingredient embeddings as recipe features '''\n",
    "hg.ndata['ingredients'] = {'recipe': torch.from_numpy(token_model.dv.vectors).float()}  # .to('cuda:0')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>date</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>user_id_contig</th>\n",
       "      <th>recipe_id_contig</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>279197</th>\n",
       "      <td>1572865</td>\n",
       "      <td>84247</td>\n",
       "      <td>2010-06-11</td>\n",
       "      <td>5</td>\n",
       "      <td>What a winner!!!  I didn't want to heat up the...</td>\n",
       "      <td>0</td>\n",
       "      <td>49001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302320</th>\n",
       "      <td>524293</td>\n",
       "      <td>90031</td>\n",
       "      <td>2007-06-25</td>\n",
       "      <td>5</td>\n",
       "      <td>This is a great recipe. However, I substituted...</td>\n",
       "      <td>1</td>\n",
       "      <td>52586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  recipe_id        date  rating  \\\n",
       "279197  1572865      84247  2010-06-11       5   \n",
       "302320   524293      90031  2007-06-25       5   \n",
       "\n",
       "                                                   review  user_id_contig  \\\n",
       "279197  What a winner!!!  I didn't want to heat up the...               0   \n",
       "302320  This is a great recipe. However, I substituted...               1   \n",
       "\n",
       "        recipe_id_contig  \n",
       "279197             49001  \n",
       "302320             52586  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' For user features, I should try 2 options:\n",
    "    1. use the review they left for the recipe\n",
    "    2. Use trainable embeddings\n",
    "'''\n",
    "interactions.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([49001, 52586, 87356,  ..., 12439, 83168, 14645], device='cuda:0')"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hg.edges(etype='rated')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME instead of, just add train, test, val masks on vertices \n",
    "# and train/test/validate with those vertices\n",
    "# memory intensive\n",
    "\n",
    "def train_test_split(graph: dgl.heterograph):\n",
    "    '''\n",
    "        Split graph for training and testing\n",
    "    '''\n",
    "    u, v = graph.edges(etype='rated')\n",
    "    \n",
    "    eids = np.arange(graph.number_of_edges('rated'))\n",
    "    eids = np.random.permutation(eids)\n",
    "    \n",
    "    test_size = int(len(eids)*0.15)  # 15% for testing\n",
    "    train_size = graph.number_of_edges('rated') - test_size  # 85% for training\n",
    "    \n",
    "    test_pos_u, test_pos_v = u[eids[:test_size]], v[eids[:test_size]]\n",
    "    train_pos_u, train_pos_v = u[eids[test_size:]], v[eids[test_size:]]\n",
    "    \n",
    "    # Find all negative edges and split them for training and testing\n",
    "    adj = ssp.coo_matrix((np.ones(len(u)), (u.cpu().numpy(), v.cpu().numpy())))\n",
    "    # adj_neg = 1 - adj.todense() - np.eye(graph.number_of_nodes())\n",
    "    adj_neg_u = 1 - adj.todense() - np.eye(graph.number_of_src_nodes('user'))\n",
    "    adj_neg_v = 1 - adj.todense() - np.eye(graph.number_of_src_nodes('recipe'))\n",
    "    neg_u = np.where(adj_neg_u != 0)\n",
    "    neg_v = np.where(adj_neg_v != 0)\n",
    "    \n",
    "    neg_eids = np.random.choice(len(neg_u), graph.number_of_edges('rated') // 2)\n",
    "    test_neg_u, test_neg_v = neg_u[neg_eids[:test_size]], neg_v[neg_eids[:test_size]]\n",
    "    train_neg_u, train_neg_v = neg_u[neg_eids[test_size:]], neg_v[neg_eids[test_size:]]\n",
    "    \n",
    "    train_g = graph.remove_edges(eids[:test_size], etype='rated')\n",
    "    \n",
    "    # oops\n",
    "    train_pos_g = dgl.heterograph({('user', 'rated', 'recipe'), (train_pos_u, train_pos_v)}, device='cuda:0')\n",
    "    train_net_g = dgl.heterograph({('user', 'rated', 'recipe'), (train_neg_u, train_neg_v)}, device='cuda:0')\n",
    "    \n",
    "    return train_g, train_pos_g, train_neg_g, test_pos_g, test_neg_g\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 408. GiB for an array with shape (236568, 231637) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-9f64ad876a33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pos_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_neg_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pos_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_neg_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-59-72f1cd07c865>\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(graph)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0madj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mssp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoo_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# adj_neg = 1 - adj.todense() - np.eye(graph.number_of_nodes())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0madj_neg_u\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_of_src_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'user'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0madj_neg_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_of_src_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'recipe'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mneg_u\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj_neg_u\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36mtodense\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;31m`\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mshares\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m         \"\"\"\n\u001b[0;32m--> 864\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0masmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/sparse/coo.py\u001b[0m in \u001b[0;36mtoarray\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;34m\"\"\"See the docstring for `spmatrix.toarray`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0mfortran\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfortran\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_contiguous\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1200\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1202\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 408. GiB for an array with shape (236568, 231637) and data type float64"
     ]
    }
   ],
   "source": [
    "train_g, train_pos_g, train_neg_g, test_pos_g, test_neg_g = train_test_split(hg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hg.edges['rated'].data['train_mask'][2] == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rated': tensor([      0,       1,       2,  ..., 1132193, 1132194, 1132197])}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train test split \n",
    "# train_eid_dict = {etype: hg.edges(etype=etype, form='eid') for etype in hg.etypes }\n",
    "\n",
    "#train_eid_dict = {'rated': (graph.edges['rated'].data['train_mask'] == 1).nonzero(as_tuple=True)[0] for etype in hg.etypes}\n",
    "#val_eid_dict   = {'rated': (graph.edges['rated'].data['test_mask'] == 2).nonzero(as_tuple=True)[0] for etype in hg.etypes}\n",
    "# {'rated': (hg.edges['rated'].data['train_mask'] == 2).nonzero(as_tuple=True)[0] for etype in hg.etypes}\n",
    "# {'rated': (hg.edges['rated'].data['train_mask'] == True).nonzero(as_tuple=True)[0] for etype in hg.etypes}\n",
    "{'rated': (hg.edges['rated'].data['train_mask'] == True).nonzero(as_tuple=True)[0] for etype in hg.etypes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize a graph\n",
    "def plot_graph(nxg):\n",
    "    ag = pgv.AGraph(strict=False, directed=True)\n",
    "    \n",
    "    for u, v, k in nxg.edges(keys=True):\n",
    "        ag.add_edge(u, v, label=k)\n",
    "\n",
    "    ag.layout('dot')\n",
    "    ag.draw('graph.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(hg.metagraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Construct a negative edge graph for an edge type being sampled\n",
    "'''\n",
    "def construct_negative_graph(graph: dgl.heterograph, k, etype):\n",
    "    utype, _, v_type = etype\n",
    "    src, dst = graph.edges(etype=etype)\n",
    "    \n",
    "    neg_src = src.repeat_interleave(k)\n",
    "    # neg_dst = \n",
    "    neg_dst = torch.randint(0, graph.num_nodes(v_type), (len(src) * k,), device='cuda:0') # shouldn't be random\n",
    "\n",
    "    return dgl.heterograph({etype: (neg_src, neg_dst)},\n",
    "                           num_nodes_dict = {ntype: graph.num_nodes(ntype) for ntype in graph.ntypes},\n",
    "                           device='cuda:0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Compute scores for an edge type in prediction '''\n",
    "class HeteroDotProductPredictor(torch.nn.Module):\n",
    "    ''' Dot predictor for heterograph edges '''\n",
    "    \n",
    "    def forward(self, graph, h, etype):\n",
    "        print(etype)\n",
    "        # assert(h)\n",
    "        with graph.local_scope():\n",
    "            # 'h' contains the node representations computed previously\n",
    "            graph.ndata['h'] = h\n",
    "            # print(graph.ntypes)\n",
    "            graph.apply_edges(dgl.function.u_dot_v('h', 'h', 'score'), etype=etype)\n",
    "\n",
    "            return graph.edges[etype].data['score']\n",
    "\n",
    "\n",
    "class ScorePredictor(torch.nn.Module):\n",
    "    def forward(self, edge_subgraph, x):\n",
    "        with edge_subgraph.local_scope():\n",
    "            edge_subgraph.ndata['x'] = x\n",
    "            for etype in edge_subgraph.canonical_etypes:\n",
    "                edge_subgraph.apply_edges(dgl.function.u_dot_v('x', 'x', 'score'), etype=etype)\n",
    "            return edge_subgraph.edata['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Dot predictor for edges '''\n",
    "class DotPredictor(torch.nn.Module):\n",
    "    \n",
    "    def forward(self, graph, feat):\n",
    "        with graph.local_scope():\n",
    "            # using the name feature\n",
    "            g.ndata['h'] = h\n",
    "\n",
    "            # compute a new edge feature named 'score' as a dot-product\n",
    "            # between source vertex feature 'feature' and destination\n",
    "            # vertex feature 'ingredients'\n",
    "            graph.apply_edges(fn.u_dot_v('h', 'h', 'score'))\n",
    "            \n",
    "            return graph.edata['score'][:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss computation\n",
    "def compute_loss(pos_score, neg_score):\n",
    "    # Margin loss \n",
    "    n_edges = pos_score.shape[0]\n",
    "    return (1 - pos_score.unsqueeze(1) + neg_score.view(n_edges, -1)).clamp(min=0).mean()\n",
    "\n",
    "# Heterogenoeuos graph loss computation\n",
    "def compute_loss_hetero(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score])\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])])\n",
    "    return F.binary_cross_entropy_with_logits(scores.squeeze(1), labels)\n",
    "\n",
    "# hinge loss\n",
    "def compute_hinge_loss(pos_score, neg_score):\n",
    "    # an example hinge loss\n",
    "    n = pos_score.shape[0]\n",
    "    return (neg_score.view(n, -1) - pos_score.view(n, -1) + 1).clamp(min=0).mean()\n",
    "\n",
    "# auc\n",
    "def compute_auc(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score]).numpy()\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]),\n",
    "                        torch.zeros(neg_score.shape[0])]).numpy()\n",
    "    return roc_auc_score(labels, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 2 layer GraphSAGE model'''\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_feats, hid_feats, out_feats):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_feats, h_feats, 'mean')\n",
    "        self.conv2 = SAGEConv(h_feats, h_feats, 'mean')\n",
    "        \n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Heterograph Relational Conv Model with 3 layers to \n",
    "    learn the representation of the nodes (embeddings)\n",
    "'''\n",
    "class RGCN(torch.nn.Module):\n",
    "    def __init__(self, in_feat_size, hid_feat_size, out_feat_size, rel_names):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = dgl.nn.HeteroGraphConv({rel: dgl.nn.GraphConv(in_feat_size,\n",
    "                                                                   hid_feat_size,\n",
    "                                                                  norm='right') for rel in rel_names},\n",
    "                                            aggregate='sum')\n",
    "\n",
    "        self.conv2 = dgl.nn.HeteroGraphConv({rel: dgl.nn.GraphConv(hid_feat_size,\n",
    "                                                                   out_feat_size,\n",
    "                                                                  norm='right') for rel in rel_names},\n",
    "                                            aggregate='sum')\n",
    "\n",
    "\n",
    "#     def forward(self, graph, node_features):\n",
    "#         h = self.conv1(graph, node_features)\n",
    "#         h = {k: F.leaky_relu(v) for k, v in h.items()}\n",
    "#         h = self.conv2(graph, h)\n",
    "\n",
    "#         return h\n",
    "    def forward(self, blocks, in_feat):\n",
    "\n",
    "        x = self.conv1(blocks[0], in_feat)\n",
    "        x = {k: F.leaky_relu(v) for k, v in x.items()}\n",
    "        x = self.conv2(blocks[1], x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.7.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgl.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "    Link Prediction Model\n",
    "'''\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, graph, in_features, hidden_features, out_features, etypes):\n",
    "        super().__init__()\n",
    "        self.rgcn = RGCN(in_features, hidden_features, out_features, etypes)\n",
    "        # self.rgcn = HeteroRGCN(graph, in_features, hidden_features, out_features)\n",
    "        # self.pred = HeteroDotProductPredictor()\n",
    "        self.pred = ScorePredictor()\n",
    "\n",
    "#     def forward(self, g, neg_g, node_feats, etype):\n",
    "#         h = self.rgcn(g, node_feats)  # features stored as self.embed in RGCN\n",
    "#         assert(h)\n",
    "#         # edge_sg = dgl.edge_subgraph(g, )\n",
    "\n",
    "#         return self.pred(g, h, etype), self.pred(neg_g, h, etype)\n",
    "    def forward(self, pos_g, neg_g, blocks, in_feat):\n",
    "        in_feat = self.rgcn(blocks, in_feat)\n",
    "        pos_score = self.pred(pos_g, in_feat)  #, 'rated')\n",
    "        neg_score = self.pred(neg_g, in_feat)  #, 'isRated')\n",
    "        \n",
    "        return pos_score, neg_score\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NegativeSampler(object):\n",
    "    def __init__(self, g, k):\n",
    "        # caches the probability distribution\n",
    "        self.weights = {\n",
    "            etype: g.in_degrees(etype=etype).float() ** 0.75\n",
    "            for _, etype, _ in g.canonical_etypes\n",
    "        }\n",
    "        self.k = k\n",
    "\n",
    "    def __call__(self, g, eids_dict):\n",
    "        result_dict = {}\n",
    "        for etype, eids in eids_dict.items():\n",
    "            src, _ = g.find_edges(eids, etype=etype)\n",
    "            src = src.repeat_interleave(self.k)\n",
    "            dst = self.weights[etype].multinomial(len(src), replacement=True)\n",
    "            result_dict[etype] = (src, dst)\n",
    "        return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dict = {'user' : torch.nn.Parameter(torch.FloatTensor(hg.num_nodes('user'), 70))}  # .to('cuda:0'))}\n",
    "torch.nn.init.xavier_uniform_(embed_dict['user'])\n",
    "\n",
    "hg.ndata['feat'] = {'user': embed_dict['user']}\n",
    "# hg.ndata['ingredients'] = {'recipe': torch.from_numpy(token_model.dv.vectors).float().to(hg.device)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes={'recipe': 231637, 'user': 236568},\n",
       "      num_edges={('recipe', 'isRated', 'user'): 1132198, ('user', 'rated', 'recipe'): 1132198},\n",
       "      metagraph=[('recipe', 'user', 'isRated'), ('user', 'recipe', 'rated')])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=5\n",
    "\n",
    "model = Model(hg, 70, 40, 1, hg.etypes)  # .to('cuda:0')\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "# train_mask = hg.edges['rated'].data['train_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_feat = hg.ndata['feat']['user']\n",
    "rec_feat = hg.ndata['ingredients']['recipe']\n",
    "\n",
    "node_features = {'user': user_feat, 'recipe': rec_feat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'isRated': tensor([      0,       1,       2,  ..., 1132195, 1132196, 1132197]),\n",
       " 'rated': tensor([      0,       1,       2,  ..., 1132195, 1132196, 1132197])}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_eid_dict = {etype: hg.edges(etype=etype, form='eid') for etype in hg.etypes }\n",
    "train_eid_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation set\n",
    "val_eid_dict = {'rated': (hg.edges['rated'].data['train_mask'] == False).nonzero(as_tuple=True)[0] for etype in hg.etypes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set\n",
    "train_eid_dict = {'rated': (hg.edges['rated'].data['train_mask'] == True).nonzero(as_tuple=True)[0] for etype in hg.etypes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = dgl.dataloading.MultiLayerFullNeighborSampler(2)\n",
    "\n",
    "dataloader2 = dgl.dataloading.EdgeDataLoader(hg,\n",
    "                                             train_eid_dict,\n",
    "                                             sampler,\n",
    "                                             negative_sampler=NegativeSampler(hg, 4),\n",
    "                                             batch_size=128,\n",
    "                                             shuffle=True,\n",
    "                                             drop_last=False,\n",
    "                                             device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "hg = hg.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Block(num_src_nodes={'recipe': 163588, 'user': 113675},\n",
       "      num_dst_nodes={'recipe': 44803, 'user': 7699},\n",
       "      num_edges={('recipe', 'isRated', 'user'): 516855, ('recipe', 'wasReviewedBy', 'user'): 516855, ('user', 'rated', 'recipe'): 515003, ('user', 'reviewed', 'recipe'): 515003, ('user', 'submitted', 'recipe'): 44803},\n",
       "      metagraph=[('recipe', 'user', 'isRated'), ('recipe', 'user', 'wasReviewedBy'), ('user', 'recipe', 'rated'), ('user', 'recipe', 'reviewed'), ('user', 'recipe', 'submitted')])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for epoch in range(10):\n",
    "#     negative_graph = construct_negative_graph(hg, k, ('user', 'rated', 'recipe'))\n",
    "#     # print(\"negative graph: {}\".format(negative_graph))\n",
    "\n",
    "#     pos_score, neg_score = model(hg, negative_graph, node_features, ('user', 'rated', 'recipe'))\n",
    "    \n",
    "#     # loss\n",
    "#     loss = compute_loss(pos_score, neg_score)\n",
    "\n",
    "#     opt.zero_grad()\n",
    "#     loss.backward()\n",
    "#     opt.step()\n",
    "\n",
    "#     print(loss.item())\n",
    "    \n",
    "#     # validation accuracy\n",
    "\n",
    "# score[('user', 'rated', 'recipe')].shape\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/6194 [00:00<20:47,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6931690573692322\n",
      "0.6931028366088867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/6194 [00:00<19:30,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6930379271507263\n",
      "0.6929725408554077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/6194 [00:01<19:27,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6928800940513611\n",
      "0.6927483081817627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/6194 [00:01<20:40,  4.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6925919651985168\n",
      "0.6924353837966919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/6194 [00:01<19:35,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6921769380569458\n",
      "0.6919278502464294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 12/6194 [00:02<20:07,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6916764974594116\n",
      "0.691350519657135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 13/6194 [00:02<20:36,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6909536719322205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 15/6194 [00:02<21:00,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6905575394630432\n",
      "0.6901613473892212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 16/6194 [00:03<20:37,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6895794868469238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 17/6194 [00:03<20:57,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6889418363571167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 19/6194 [00:03<20:25,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6884115934371948\n",
      "0.6878353357315063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 21/6194 [00:04<20:25,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.686949610710144\n",
      "0.6861189007759094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 23/6194 [00:04<21:05,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6852006316184998\n",
      "0.6844111680984497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 25/6194 [00:04<20:28,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6834040880203247\n",
      "0.6821137070655823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 27/6194 [00:05<20:03,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6807791590690613\n",
      "0.6798431873321533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 29/6194 [00:05<20:04,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6780838370323181\n",
      "0.6770498156547546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 31/6194 [00:06<19:14,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6746453046798706\n",
      "0.6727421283721924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 33/6194 [00:06<19:23,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6708905100822449\n",
      "0.669196367263794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 35/6194 [00:06<19:26,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6663357019424438\n",
      "0.6643860936164856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 36/6194 [00:07<19:31,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6616536974906921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 38/6194 [00:07<19:52,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6603516936302185\n",
      "0.6562414169311523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 40/6194 [00:07<19:55,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65362948179245\n",
      "0.6507973670959473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 41/6194 [00:08<20:22,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6471969485282898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 43/6194 [00:08<20:29,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6451069712638855\n",
      "0.640617847442627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 44/6194 [00:08<20:17,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6382246613502502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 46/6194 [00:09<20:07,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6325049996376038\n",
      "0.6305027604103088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 48/6194 [00:09<19:58,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.625185489654541\n",
      "0.6204826831817627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 50/6194 [00:09<19:33,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6157106161117554\n",
      "0.6110453605651855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 52/6194 [00:10<21:19,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6062970161437988\n",
      "0.6004830598831177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 54/6194 [00:10<21:28,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5957850813865662\n",
      "0.5898532271385193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 56/6194 [00:11<20:31,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.582658588886261\n",
      "0.5776313543319702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 58/6194 [00:11<19:46,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5716444253921509\n",
      "0.5642405152320862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 60/6194 [00:11<20:08,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5574548244476318\n",
      "0.5518512725830078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 62/6194 [00:12<19:35,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5411519408226013\n",
      "0.5361733436584473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 63/6194 [00:12<19:38,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.528210461139679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 65/6194 [00:12<20:38,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5213608741760254\n",
      "0.5097223520278931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 66/6194 [00:13<20:06,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5025468468666077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 67/6194 [00:13<20:17,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4962252974510193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 68/6194 [00:13<22:36,  4.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4896339774131775\n",
      "0.47957363724708557"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 70/6194 [00:13<21:00,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.46856486797332764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 72/6194 [00:14<19:59,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45964598655700684\n",
      "0.458944171667099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 74/6194 [00:14<19:29,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44320690631866455\n",
      "0.4317178726196289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 75/6194 [00:14<19:31,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41821983456611633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 76/6194 [00:15<20:49,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4169366657733917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|â–         | 78/6194 [00:15<20:12,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40397390723228455\n",
      "0.39737051725387573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|â–         | 80/6194 [00:15<19:19,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38507184386253357\n",
      "0.37736207246780396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|â–         | 82/6194 [00:16<19:46,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3632936179637909\n",
      "0.3552424907684326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|â–         | 83/6194 [00:16<20:09,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34703829884529114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|â–         | 84/6194 [00:16<20:56,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33227095007896423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|â–         | 86/6194 [00:17<20:30,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3213173449039459\n",
      "0.3129938542842865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|â–         | 88/6194 [00:17<19:51,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3026718199253082\n",
      "0.2939436137676239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|â–         | 90/6194 [00:17<20:01,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2837427258491516\n",
      "0.27459847927093506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|â–         | 92/6194 [00:18<19:34,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2574712932109833\n",
      "0.25336116552352905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 94/6194 [00:18<19:11,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2417244017124176\n",
      "0.2362724244594574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 96/6194 [00:19<19:37,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22280970215797424\n",
      "0.2155151069164276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 98/6194 [00:19<18:51,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21918240189552307\n",
      "0.1991904079914093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 100/6194 [00:19<19:10,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1898353397846222\n",
      "0.18166542053222656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 102/6194 [00:20<19:38,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1845439076423645\n",
      "0.1679472029209137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 104/6194 [00:20<19:53,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1613769233226776\n",
      "0.15784598886966705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 106/6194 [00:20<19:38,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15053808689117432\n",
      "0.14339357614517212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|â–         | 107/6194 [00:21<19:47,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13456463813781738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 109/6194 [00:21<20:05,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1291411966085434\n",
      "0.12117983400821686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|â–         | 110/6194 [00:21<20:01,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11745069175958633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 112/6194 [00:22<20:42,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10911988466978073\n",
      "0.11058544367551804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 114/6194 [00:22<20:19,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10736220329999924\n",
      "0.09697875380516052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 116/6194 [00:23<21:18,  4.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09126818925142288\n",
      "0.09512175619602203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 118/6194 [00:23<20:50,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08918921649456024\n",
      "0.07915637642145157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 120/6194 [00:23<20:08,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07703850418329239\n",
      "0.0747142881155014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 122/6194 [00:24<20:36,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06649245321750641\n",
      "0.06917354464530945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 124/6194 [00:24<19:53,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06211234629154205\n",
      "0.05906194821000099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|â–         | 125/6194 [00:24<20:17,  4.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0674847662448883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|â–         | 126/6194 [00:25<20:41,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05425361916422844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 128/6194 [00:25<20:19,  4.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06112289056181908\n",
      "0.05734077841043472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|â–         | 129/6194 [00:25<20:07,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.048056792467832565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 131/6194 [00:26<20:24,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05315603315830231\n",
      "0.049149610102176666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 133/6194 [00:26<19:58,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04329296201467514\n",
      "0.04337528720498085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|â–         | 134/6194 [00:26<19:57,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0379391647875309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 136/6194 [00:27<20:03,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.046033747494220734\n",
      "0.04334692284464836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 138/6194 [00:27<20:27,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.036803435534238815\n",
      "0.03517022728919983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 140/6194 [00:27<20:00,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.033649422228336334\n",
      "0.03494492173194885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 142/6194 [00:28<19:43,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.031358614563941956\n",
      "0.03132996708154678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|â–         | 143/6194 [00:28<20:34,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03294241055846214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|â–         | 144/6194 [00:28<23:11,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.029981229454278946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 146/6194 [00:29<21:09,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03009893000125885\n",
      "0.027961838990449905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 148/6194 [00:29<19:53,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.029480500146746635\n",
      "0.026359079405665398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 150/6194 [00:29<19:54,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.026375140994787216\n",
      "0.025053003802895546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|â–         | 151/6194 [00:30<19:45,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.024078264832496643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 153/6194 [00:30<20:43,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02807074412703514\n",
      "0.025230342522263527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 155/6194 [00:30<20:04,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.022569457069039345\n",
      "0.021402625367045403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 157/6194 [00:31<19:43,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.020999561995267868\n",
      "0.021452363580465317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 159/6194 [00:31<19:58,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.021516527980566025\n",
      "0.019638625904917717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 161/6194 [00:32<20:04,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.018879469484090805\n",
      "0.017032839357852936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 163/6194 [00:32<19:11,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.018605709075927734\n",
      "0.01858840137720108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 165/6194 [00:32<19:18,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01841989904642105\n",
      "0.017416153103113174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|â–Ž         | 166/6194 [00:33<19:46,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.017562780529260635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|â–Ž         | 167/6194 [00:33<20:27,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.017239725217223167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|â–Ž         | 168/6194 [00:33<20:53,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.018652815371751785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 170/6194 [00:34<21:50,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014114596880972385\n",
      "0.020769156515598297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 172/6194 [00:34<20:52,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014692728407680988\n",
      "0.01708448864519596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 174/6194 [00:34<20:11,  4.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.013770339079201221\n",
      "0.013550725765526295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 176/6194 [00:35<19:56,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.013142875395715237\n",
      "0.014062770642340183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 178/6194 [00:35<18:57,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012532751075923443\n",
      "0.014915835112333298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 180/6194 [00:35<19:09,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015007569454610348\n",
      "0.015900570899248123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 182/6194 [00:36<19:15,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011218897998332977\n",
      "0.011463647708296776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|â–Ž         | 183/6194 [00:36<20:06,  4.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012379529885947704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 185/6194 [00:36<19:52,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.013941925950348377\n",
      "0.0108179971575737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 187/6194 [00:37<18:55,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011215431615710258\n",
      "0.016557976603507996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 189/6194 [00:37<18:52,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011217441409826279\n",
      "0.014858797192573547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|â–Ž         | 190/6194 [00:37<19:00,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009061486460268497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|â–Ž         | 191/6194 [00:38<20:09,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012140271253883839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|â–Ž         | 192/6194 [00:38<20:11,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010831507854163647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|â–Ž         | 193/6194 [00:38<20:09,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008095336146652699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 195/6194 [00:38<20:22,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012925926595926285\n",
      "0.011224363930523396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 197/6194 [00:39<20:28,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01201404258608818\n",
      "0.010883968323469162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 199/6194 [00:39<20:33,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010220387950539589\n",
      "0.008281300775706768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 200/6194 [00:40<20:00,  4.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01226048357784748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epoch = 200\n",
    "score = {}\n",
    "for input_nodes, pos_graph, neg_graph, blocks in tqdm.tqdm(dataloader2):\n",
    "    if epoch > 0:\n",
    "    # move to gpu\n",
    "#     blocks = [b.to(torch.device('cuda')) for b in blocks]\n",
    "#     pos_graph = pos_graph.to(torch.device('cuda'))\n",
    "#     neg_graph = neg_graph.to(torch.device('cuda'))\n",
    "    \n",
    "        node_feat = {'user': blocks[0].srcdata['feat']['user'], \n",
    "                     'recipe': blocks[0].srcdata['ingredients']['recipe']}\n",
    "        # print(node_feat)\n",
    "\n",
    "        pos_score, neg_score = model(pos_graph, neg_graph, blocks, node_feat)\n",
    "\n",
    "        loss = compute_loss_hetero(pos_score[('user', 'rated', 'recipe')],\n",
    "                                   neg_score[('user', 'rated', 'recipe')])\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        # print(loss.item())\n",
    "        epoch = epoch - 1\n",
    "#        score = blocks[0]\n",
    "    else:\n",
    "        break\n",
    "        print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt to make dataset, rather than make the graph from scratch with dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-18bf08814031>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.device_count()\n",
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eids = hg.edge_ids(hg.edges(etype='rated')[0], hg.edges(etype='rated')[1], etype='rated')\n",
    "# hg.edges(etype='rated')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = dgl.dataloading.EdgeDataLoader(hg, \n",
    "                                            {'rated': train_eids},\n",
    "                                            dgl.dataloading.MultiLayerFullNeighborSampler(3),\n",
    "                                            batch_size=64,\n",
    "                                            shuffle=True,\n",
    "                                            device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (rgcn): RGCN(\n",
       "    (conv1): HeteroGraphConv(\n",
       "      (mods): ModuleDict(\n",
       "        (isRated): GraphConv(in=70, out=40, normalization=right, activation=None)\n",
       "        (wasReviewedBy): GraphConv(in=70, out=40, normalization=right, activation=None)\n",
       "        (rated): GraphConv(in=70, out=40, normalization=right, activation=None)\n",
       "        (reviewed): GraphConv(in=70, out=40, normalization=right, activation=None)\n",
       "        (submitted): GraphConv(in=70, out=40, normalization=right, activation=None)\n",
       "      )\n",
       "    )\n",
       "    (conv2): HeteroGraphConv(\n",
       "      (mods): ModuleDict(\n",
       "        (isRated): GraphConv(in=40, out=1, normalization=right, activation=None)\n",
       "        (wasReviewedBy): GraphConv(in=40, out=1, normalization=right, activation=None)\n",
       "        (rated): GraphConv(in=40, out=1, normalization=right, activation=None)\n",
       "        (reviewed): GraphConv(in=40, out=1, normalization=right, activation=None)\n",
       "        (submitted): GraphConv(in=40, out=1, normalization=right, activation=None)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pred): ScorePredictor()\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (rgcn): RGCN(\n",
       "    (conv1): HeteroGraphConv(\n",
       "      (mods): ModuleDict(\n",
       "        (isRated): GraphConv(in=70, out=40, normalization=right, activation=None)\n",
       "        (wasReviewedBy): GraphConv(in=70, out=40, normalization=right, activation=None)\n",
       "        (rated): GraphConv(in=70, out=40, normalization=right, activation=None)\n",
       "        (reviewed): GraphConv(in=70, out=40, normalization=right, activation=None)\n",
       "        (submitted): GraphConv(in=70, out=40, normalization=right, activation=None)\n",
       "      )\n",
       "    )\n",
       "    (conv2): HeteroGraphConv(\n",
       "      (mods): ModuleDict(\n",
       "        (isRated): GraphConv(in=40, out=1, normalization=right, activation=None)\n",
       "        (wasReviewedBy): GraphConv(in=40, out=1, normalization=right, activation=None)\n",
       "        (rated): GraphConv(in=40, out=1, normalization=right, activation=None)\n",
       "        (reviewed): GraphConv(in=40, out=1, normalization=right, activation=None)\n",
       "        (submitted): GraphConv(in=40, out=1, normalization=right, activation=None)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pred): ScorePredictor()\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hits(edges_df, h, h_test):\n",
    "    ''' Get list of hits'''\n",
    "    hist = []\n",
    "    edges = edges_df\n",
    "    for i in range(h.shape[0]):\n",
    "        true_edges = list(edges[edges.asin == i].recipe_id)\n",
    "        dist = torch.cdist(h_test[[i]], h)\n",
    "        top_k = torch.topk(dist, k=500, largest=False)[1]\n",
    "        hit = 0\n",
    "        for j in true_edges:\n",
    "            if j in top_k:\n",
    "                hit = 1\n",
    "                break\n",
    "        hits.apend(hit)\n",
    "    return hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'h' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-362b6820fa01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# if hit:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# hits =\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mget_hits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_eid_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_pos_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'h' is not defined"
     ]
    }
   ],
   "source": [
    "# if hit:\n",
    "# hits = \n",
    "get_hits(val_eid_dict, h, model(test_pos_g, node_features))\n",
    "print(np.mean(hits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "DGLError",
     "evalue": "[19:57:54] /opt/dgl/src/array/cpu/csr_get_data.cc:47: Check failed: (rowlen == collen) || (rowlen == 1) || (collen == 1): Invalid row and col id array.\nStack trace:\n  [bt] (0) /home/trique/.local/lib/python3.8/site-packages/dgl/libdgl.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x4f) [0x7f7128db93bf]\n  [bt] (1) /home/trique/.local/lib/python3.8/site-packages/dgl/libdgl.so(dgl::runtime::NDArray dgl::aten::impl::CSRGetData<(DLDeviceType)1, long, long>(dgl::aten::CSRMatrix, dgl::runtime::NDArray, dgl::runtime::NDArray, bool, dgl::runtime::NDArray, long)+0xdd) [0x7f7128df083d]\n  [bt] (2) /home/trique/.local/lib/python3.8/site-packages/dgl/libdgl.so(dgl::runtime::NDArray dgl::aten::impl::CSRGetData<(DLDeviceType)1, long>(dgl::aten::CSRMatrix, dgl::runtime::NDArray, dgl::runtime::NDArray)+0x13f) [0x7f7128db4c7f]\n  [bt] (3) /home/trique/.local/lib/python3.8/site-packages/dgl/libdgl.so(dgl::aten::CSRGetData(dgl::aten::CSRMatrix, dgl::runtime::NDArray, dgl::runtime::NDArray)+0x7d2) [0x7f7128dad592]\n  [bt] (4) /home/trique/.local/lib/python3.8/site-packages/dgl/libdgl.so(dgl::UnitGraph::CSR::EdgeIdsOne(unsigned long, dgl::runtime::NDArray, dgl::runtime::NDArray) const+0x56) [0x7f712970d596]\n  [bt] (5) /home/trique/.local/lib/python3.8/site-packages/dgl/libdgl.so(dgl::UnitGraph::EdgeIdsOne(unsigned long, dgl::runtime::NDArray, dgl::runtime::NDArray) const+0x8d) [0x7f712970752d]\n  [bt] (6) /home/trique/.local/lib/python3.8/site-packages/dgl/libdgl.so(dgl::HeteroGraph::EdgeIdsOne(unsigned long, dgl::runtime::NDArray, dgl::runtime::NDArray) const+0x66) [0x7f712960aac6]\n  [bt] (7) /home/trique/.local/lib/python3.8/site-packages/dgl/libdgl.so(+0xe0c25c) [0x7f712961225c]\n  [bt] (8) /home/trique/.local/lib/python3.8/site-packages/dgl/libdgl.so(DGLFuncCall+0x48) [0x7f712959f518]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDGLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-6a6d499625b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'user'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'recipe'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'user'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rated'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'recipe'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/dgl/heterograph.py\u001b[0m in \u001b[0;36medge_ids\u001b[0;34m(self, u, v, force_multi, return_uv, etype)\u001b[0m\n\u001b[1;32m   3084\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_ids_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_etype_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3085\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3086\u001b[0;31m             \u001b[0meid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_ids_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_etype_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3087\u001b[0m             \u001b[0mis_neg_one\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3088\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_neg_one\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/dgl/heterograph_index.py\u001b[0m in \u001b[0;36medge_ids_one\u001b[0;34m(self, etype, u, v)\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0medge\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \"\"\"\n\u001b[0;32m--> 440\u001b[0;31m         eid = F.from_dgl_nd(_CAPI_DGLHeteroEdgeIdsOne(\n\u001b[0m\u001b[1;32m    441\u001b[0m             self, int(etype), F.to_dgl_nd(u), F.to_dgl_nd(v)))\n\u001b[1;32m    442\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0meid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mdgl/_ffi/_cython/./function.pxi\u001b[0m in \u001b[0;36mdgl._ffi._cy3.core.FunctionBase.__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mdgl/_ffi/_cython/./function.pxi\u001b[0m in \u001b[0;36mdgl._ffi._cy3.core.FuncCall\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mdgl/_ffi/_cython/./base.pxi\u001b[0m in \u001b[0;36mdgl._ffi._cy3.core.CALL\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mDGLError\u001b[0m: [19:57:54] /opt/dgl/src/array/cpu/csr_get_data.cc:47: Check failed: (rowlen == collen) || (rowlen == 1) || (collen == 1): Invalid row and col id array.\nStack trace:\n  [bt] (0) /home/trique/.local/lib/python3.8/site-packages/dgl/libdgl.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x4f) [0x7f7128db93bf]\n  [bt] (1) /home/trique/.local/lib/python3.8/site-packages/dgl/libdgl.so(dgl::runtime::NDArray dgl::aten::impl::CSRGetData<(DLDeviceType)1, long, long>(dgl::aten::CSRMatrix, dgl::runtime::NDArray, dgl::runtime::NDArray, bool, dgl::runtime::NDArray, long)+0xdd) [0x7f7128df083d]\n  [bt] (2) /home/trique/.local/lib/python3.8/site-packages/dgl/libdgl.so(dgl::runtime::NDArray dgl::aten::impl::CSRGetData<(DLDeviceType)1, long>(dgl::aten::CSRMatrix, dgl::runtime::NDArray, dgl::runtime::NDArray)+0x13f) [0x7f7128db4c7f]\n  [bt] (3) /home/trique/.local/lib/python3.8/site-packages/dgl/libdgl.so(dgl::aten::CSRGetData(dgl::aten::CSRMatrix, dgl::runtime::NDArray, dgl::runtime::NDArray)+0x7d2) [0x7f7128dad592]\n  [bt] (4) /home/trique/.local/lib/python3.8/site-packages/dgl/libdgl.so(dgl::UnitGraph::CSR::EdgeIdsOne(unsigned long, dgl::runtime::NDArray, dgl::runtime::NDArray) const+0x56) [0x7f712970d596]\n  [bt] (5) /home/trique/.local/lib/python3.8/site-packages/dgl/libdgl.so(dgl::UnitGraph::EdgeIdsOne(unsigned long, dgl::runtime::NDArray, dgl::runtime::NDArray) const+0x8d) [0x7f712970752d]\n  [bt] (6) /home/trique/.local/lib/python3.8/site-packages/dgl/libdgl.so(dgl::HeteroGraph::EdgeIdsOne(unsigned long, dgl::runtime::NDArray, dgl::runtime::NDArray) const+0x66) [0x7f712960aac6]\n  [bt] (7) /home/trique/.local/lib/python3.8/site-packages/dgl/libdgl.so(+0xe0c25c) [0x7f712961225c]\n  [bt] (8) /home/trique/.local/lib/python3.8/site-packages/dgl/libdgl.so(DGLFuncCall+0x48) [0x7f712959f518]\n\n"
     ]
    }
   ],
   "source": [
    "hg.edge_ids(hg.nodes('user'), hg.nodes('recipe'), etype=('user', 'rated', 'recipe'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 5, 5,  ..., 5, 5, 5])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hg.edata['rating'][('user', 'rated', 'recipe')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "DGLError",
     "evalue": "Edge type \"score\" does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDGLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-03d321304f2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'all'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/dgl/view.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;34m\"\"\"Return all the edges.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHeteroEdgeDataView\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMutableMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/dgl/heterograph.py\u001b[0m in \u001b[0;36mall_edges\u001b[0;34m(self, form, order, etype)\u001b[0m\n\u001b[1;32m   3406\u001b[0m         \u001b[0mout_edges\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3407\u001b[0m         \"\"\"\n\u001b[0;32m-> 3408\u001b[0;31m         \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_etype_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mform\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'all'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3410\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/dgl/heterograph.py\u001b[0m in \u001b[0;36mget_etype_id\u001b[0;34m(self, etype)\u001b[0m\n\u001b[1;32m   1259\u001b[0m                                'edge types.')\n\u001b[1;32m   1260\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1261\u001b[0;31m         \u001b[0metid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_etypes_invmap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_canonical_etype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0metid\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mDGLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Edge type \"{}\" does not exist.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/dgl/heterograph.py\u001b[0m in \u001b[0;36mto_canonical_etype\u001b[0;34m(self, etype)\u001b[0m\n\u001b[1;32m   1149\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_etype2canonical\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mDGLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Edge type \"{}\" does not exist.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m                 raise DGLError('Edge type \"%s\" is ambiguous. Please use canonical edge type '\n",
      "\u001b[0;31mDGLError\u001b[0m: Edge type \"score\" does not exist."
     ]
    }
   ],
   "source": [
    "hg.edges(form='all', etype='score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "DGLError",
     "evalue": "Invalid key \"_TYPE\". Must be one of the edge types.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDGLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-816a7c9bc474>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mETYPE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/dgl/heterograph.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2230\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metypes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2231\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mDGLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid key \"{}\". Must be one of the edge types.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metypes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDGLError\u001b[0m: Invalid key \"_TYPE\". Must be one of the edge types."
     ]
    }
   ],
   "source": [
    "hg[dgl.ETYPE]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
